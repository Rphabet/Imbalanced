{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Hybrid of Resampling and Cost Sensitive Methods"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "from imblearn.combine import SMOTEENN, SMOTETomek"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "sklearn reference에서는 SMOTE ENN이 Noisy 제거에 SMOTETomek 보다 나은 결과를 제시한다고 말하고 있음"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [],
   "source": [
    "def sampling_smote_enn(x_input, y_input, smote=None, enn=None, sampling_strategy='auto'):\n",
    "    \"\"\"\n",
    "    :param x_input: x data 입력\n",
    "    :param y_input: y data 입력\n",
    "    :param smote: SMOTE 객체 입력\n",
    "    :param enn: ENN 객체 입력\n",
    "    :param sampling_strategy: 딕셔너리 구조로 입력\n",
    "    :return: x_sme, y_sme\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "    from imblearn.combine import SMOTEENN\n",
    "    sme = SMOTEENN(smote=smote,\n",
    "                   enn=enn,\n",
    "                   sampling_strategy=sampling_strategy,\n",
    "                   random_state=42,\n",
    "                   n_jobs=-1)\n",
    "\n",
    "    x_sme, y_sme = sme.fit_resample(x_input, y_input)\n",
    "\n",
    "    print(\"Before SMOTE ENN....\")\n",
    "    print(\"The shape of your X data: \", x_input.shape)\n",
    "    print(\"The shape of your y data: \", y_input.shape)\n",
    "    print(\"Label Counts : \\n\", pd.Series(y_input).value_counts().sort_index())\n",
    "    print('\\n')\n",
    "    print(\"After SMOTE ENN Applied....\")\n",
    "    print(\"The shape of your X_SME data: \", x_sme.shape)\n",
    "    print(\"The shape of your y_SME data: \", y_sme.shape)\n",
    "    print(\"Label Counts : \\n\", pd.Series(y_sme).value_counts().sort_index())\n",
    "\n",
    "    return x_sme, y_sme"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "((75000, 23), (25000, 23))"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs = pd.read_csv('./processed.csv')\n",
    "train = pd.read_csv('./train.csv')\n",
    "test = pd.read_csv('./test.csv')\n",
    "train.shape, test.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "dfs['Month'] = le.fit_transform(dfs['Month'])\n",
    "train['Month'] = le.transform(train['Month'])\n",
    "test['Month'] = le.transform(test['Month'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Customer_ID :  12500\n",
      "Month :  8\n",
      "Credit_Mix :  3\n",
      "Credit_History_Age :  2\n",
      "Payment_of_Min_Amount :  3\n",
      "Payment_Behaviour :  6\n"
     ]
    }
   ],
   "source": [
    "target = 'Credit_Score'\n",
    "cat_col = ['Customer_ID', 'Month', 'Credit_Mix', 'Credit_History_Age',\n",
    "           'Payment_of_Min_Amount', 'Payment_Behaviour']\n",
    "cat_dims = {}\n",
    "for col in cat_col:\n",
    "    cat_dims[col] = len(list(dfs[col].unique()))\n",
    "    print(col, ': ', cat_dims[col])\n",
    "cat_col_idx = [list(dfs.columns).index(col) for col in cat_col]\n",
    "cat_col_dims = [cat_dims[col] for col in cat_col]\n",
    "all_col_list = [col for col in dfs.columns if col !=target]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "x_train = train.loc[:, all_col_list].values\n",
    "y_train = train.loc[:, target].values\n",
    "x_test = test.loc[:, all_col_list].values\n",
    "y_test = test.loc[:, target].values"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE, SMOTENC\n",
    "from imblearn.under_sampling import EditedNearestNeighbours, TomekLinks"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "enn = EditedNearestNeighbours(n_jobs=-1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "smoteenn = SMOTEENN(smote=SMOTE(),\n",
    "                    enn=enn,\n",
    "                    random_state=42,\n",
    "                    n_jobs=-1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "x_sme, y_sme = smoteenn.fit_resample(x_train, y_train)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "data": {
      "text/plain": "0    40214\n2    31570\n1    15637\ndtype: int64"
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(y_sme).value_counts()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "(87421, 21)"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_sme.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "data": {
      "text/plain": "(87421,)"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_sme.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier(n_jobs=-1, random_state=42)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "data": {
      "text/plain": "RandomForestClassifier(n_jobs=-1, random_state=42)",
      "text/html": "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(n_jobs=-1, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(n_jobs=-1, random_state=42)</pre></div></div></div></div></div>"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc.fit(x_sme, y_sme)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "data": {
      "text/plain": "0.6858"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc.score(x_test, y_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, plot_confusion_matrix"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "y_pred = rfc.predict(x_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.86      0.74      7216\n",
      "           1       0.80      0.57      0.67     12960\n",
      "           2       0.58      0.74      0.65      4824\n",
      "\n",
      "    accuracy                           0.69     25000\n",
      "   macro avg       0.67      0.72      0.68     25000\n",
      "weighted avg       0.71      0.69      0.68     25000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_true=y_test, y_pred=y_pred))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ben/miniforge3/envs/tf_mini/lib/python3.8/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function plot_confusion_matrix is deprecated; Function `plot_confusion_matrix` is deprecated in 1.0 and will be removed in 1.2. Use one of the class methods: ConfusionMatrixDisplay.from_predictions or ConfusionMatrixDisplay.from_estimator.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x17dda07c0>"
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 2 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(y_true=y_test, X=x_test, estimator=rfc)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [],
   "source": [
    "smote = SMOTE(k_neighbors=7)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before SMOTE ENN....\n",
      "The shape of your X data:  (75000, 21)\n",
      "The shape of your y data:  (75000,)\n",
      "Label Counts : \n",
      " 0    21782\n",
      "1    40214\n",
      "2    13004\n",
      "dtype: int64\n",
      "\n",
      "\n",
      "After SMOTE ENN Applied....\n",
      "The shape of your X_SME data:  (72981, 21)\n",
      "The shape of your y_SME data:  (72981,)\n",
      "Label Counts : \n",
      " 0    27039\n",
      "1    15275\n",
      "2    30667\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "x_sme, y_sme = sampling_smote_enn(x_train, y_train, smote=smote, enn=None, sampling_strategy='auto')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "지금 ENN으로 너무 많은 다수 데이터를 제거한 것으로 보임. 정보 유실이 심각하게 우려됨"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before SMOTE ENN....\n",
      "The shape of your X data:  (75000, 21)\n",
      "The shape of your y data:  (75000,)\n",
      "Label Counts : \n",
      " 0    21782\n",
      "1    40214\n",
      "2    13004\n",
      "dtype: int64\n",
      "\n",
      "\n",
      "After SMOTE ENN Applied....\n",
      "The shape of your X_SME data:  (74703, 21)\n",
      "The shape of your y_SME data:  (74703,)\n",
      "Label Counts : \n",
      " 0    27507\n",
      "1    15619\n",
      "2    31577\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "x_sme, y_sme = sampling_smote_enn(x_train, y_train, sampling_strategy='auto')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [
    {
     "data": {
      "text/plain": "array([0.90526048, 1.5942762 , 0.7885803 ])"
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = compute_class_weight(class_weight = \"balanced\" ,\n",
    "                               classes=np.unique(y_sme),\n",
    "                               y = y_sme)\n",
    "\n",
    "weights"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier(random_state=42, n_jobs=-1, class_weight='balanced')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [
    {
     "data": {
      "text/plain": "RandomForestClassifier(class_weight='balanced', n_jobs=-1, random_state=42)",
      "text/html": "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(class_weight=&#x27;balanced&#x27;, n_jobs=-1, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(class_weight=&#x27;balanced&#x27;, n_jobs=-1, random_state=42)</pre></div></div></div></div></div>"
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc.fit(x_sme, y_sme)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [
    {
     "data": {
      "text/plain": "0.9999866136567473"
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc.score(x_sme, y_sme)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [
    {
     "data": {
      "text/plain": "0.67392"
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc.score(x_test, y_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [],
   "source": [
    "y_pred = rfc.predict(x_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.77      0.71      7216\n",
      "           1       0.78      0.60      0.67     12960\n",
      "           2       0.53      0.75      0.62      4824\n",
      "\n",
      "    accuracy                           0.67     25000\n",
      "   macro avg       0.66      0.70      0.67     25000\n",
      "weighted avg       0.70      0.67      0.68     25000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_true=y_test, y_pred=y_pred))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pytorch_tabnet.tab_model import TabNetClassifier\n",
    "from pytorch_tabnet.pretraining import TabNetPretrainer\n",
    "from pytorch_tabnet.metrics import Metric\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, f1_score, confusion_matrix"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [],
   "source": [
    "class F1_Score(Metric):\n",
    "    def __init__(self):\n",
    "        self._name = 'f1'\n",
    "        self._maximize = True\n",
    "\n",
    "    def __call__(self, y_true, y_score):\n",
    "        score = f1_score(y_true, (y_score[:, 1]>0.5)*1, average='micro')\n",
    "        return score"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Customer_ID :  12500\n",
      "Month :  8\n",
      "Credit_Mix :  3\n",
      "Credit_History_Age :  2\n",
      "Payment_of_Min_Amount :  3\n",
      "Payment_Behaviour :  6\n"
     ]
    }
   ],
   "source": [
    "target = 'Credit_Score'\n",
    "cat_col = ['Customer_ID', 'Month', 'Credit_Mix', 'Credit_History_Age',\n",
    "           'Payment_of_Min_Amount', 'Payment_Behaviour']\n",
    "cat_dims = {}\n",
    "for col in cat_col:\n",
    "    cat_dims[col] = len(list(dfs[col].unique()))\n",
    "    print(col, ': ', cat_dims[col])\n",
    "cat_col_idx = [list(dfs.columns).index(col) for col in cat_col]\n",
    "cat_col_dims = [cat_dims[col] for col in cat_col]\n",
    "all_col_list = [col for col in dfs.columns if col !=target]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [],
   "source": [
    "x_train = train.loc[:, all_col_list].values\n",
    "y_train = train.loc[:, target].values\n",
    "x_test = test.loc[:, all_col_list].values\n",
    "y_test = test.loc[:, target].values"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before SMOTE ENN....\n",
      "The shape of your X data:  (75000, 21)\n",
      "The shape of your y data:  (75000,)\n",
      "Label Counts : \n",
      " 0    21782\n",
      "1    40214\n",
      "2    13004\n",
      "dtype: int64\n",
      "\n",
      "\n",
      "After SMOTE ENN Applied....\n",
      "The shape of your X_SME data:  (74703, 21)\n",
      "The shape of your y_SME data:  (74703,)\n",
      "Label Counts : \n",
      " 0    27507\n",
      "1    15619\n",
      "2    31577\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "x_sme, y_sme = sampling_smote_enn(x_train, y_train)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [
    {
     "data": {
      "text/plain": "array([0.90526048, 1.5942762 , 0.7885803 ])"
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = compute_class_weight(class_weight = \"balanced\" ,\n",
    "                               classes=np.unique(y_sme),\n",
    "                               y = y_sme)\n",
    "\n",
    "weights"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device used : cpu\n",
      "No early stopping will be performed, last training weights will be used.\n",
      "epoch 0  | loss: 4.34643 |  0:00:15s\n",
      "epoch 1  | loss: 2.27185 |  0:00:30s\n",
      "epoch 2  | loss: 1.75736 |  0:00:46s\n",
      "epoch 3  | loss: 1.39725 |  0:01:00s\n",
      "epoch 4  | loss: 1.2126  |  0:01:16s\n",
      "epoch 5  | loss: 1.07706 |  0:01:34s\n",
      "epoch 6  | loss: 1.04188 |  0:01:50s\n",
      "epoch 7  | loss: 1.02312 |  0:02:11s\n",
      "epoch 8  | loss: 1.01316 |  0:02:30s\n",
      "epoch 9  | loss: 0.99287 |  0:02:46s\n",
      "epoch 10 | loss: 0.97379 |  0:03:00s\n",
      "epoch 11 | loss: 0.96142 |  0:03:15s\n",
      "epoch 12 | loss: 0.95093 |  0:03:29s\n",
      "epoch 13 | loss: 0.94367 |  0:03:43s\n",
      "epoch 14 | loss: 0.93977 |  0:03:54s\n",
      "epoch 15 | loss: 0.93543 |  0:04:06s\n",
      "epoch 16 | loss: 0.93248 |  0:04:17s\n",
      "epoch 17 | loss: 0.93146 |  0:04:29s\n",
      "epoch 18 | loss: 0.92711 |  0:04:41s\n",
      "epoch 19 | loss: 0.92042 |  0:04:52s\n",
      "epoch 20 | loss: 0.91453 |  0:05:04s\n",
      "epoch 21 | loss: 0.90979 |  0:05:15s\n",
      "epoch 22 | loss: 0.90661 |  0:05:27s\n",
      "epoch 23 | loss: 0.90376 |  0:05:38s\n",
      "epoch 24 | loss: 0.90141 |  0:05:49s\n",
      "epoch 25 | loss: 0.89762 |  0:06:01s\n",
      "epoch 26 | loss: 0.89431 |  0:06:12s\n",
      "epoch 27 | loss: 0.89359 |  0:06:24s\n",
      "epoch 28 | loss: 0.89214 |  0:06:36s\n",
      "epoch 29 | loss: 0.88935 |  0:06:47s\n",
      "epoch 30 | loss: 0.88927 |  0:07:00s\n",
      "epoch 31 | loss: 0.88732 |  0:07:13s\n",
      "epoch 32 | loss: 0.88561 |  0:07:26s\n",
      "epoch 33 | loss: 0.88409 |  0:07:40s\n",
      "epoch 34 | loss: 0.88278 |  0:07:51s\n",
      "epoch 35 | loss: 0.88318 |  0:08:05s\n",
      "epoch 36 | loss: 0.87881 |  0:08:22s\n",
      "epoch 37 | loss: 0.87547 |  0:08:37s\n",
      "epoch 38 | loss: 0.87436 |  0:08:50s\n",
      "epoch 39 | loss: 0.87034 |  0:09:02s\n",
      "epoch 40 | loss: 0.86754 |  0:09:19s\n",
      "epoch 41 | loss: 0.86436 |  0:09:37s\n",
      "epoch 42 | loss: 0.86259 |  0:09:57s\n",
      "epoch 43 | loss: 0.85871 |  0:10:15s\n",
      "epoch 44 | loss: 0.85475 |  0:10:30s\n",
      "epoch 45 | loss: 0.85092 |  0:10:44s\n",
      "epoch 46 | loss: 0.85064 |  0:11:01s\n",
      "epoch 47 | loss: 0.84572 |  0:11:16s\n",
      "epoch 48 | loss: 0.84347 |  0:11:34s\n",
      "epoch 49 | loss: 0.84276 |  0:11:48s\n",
      "epoch 50 | loss: 0.83974 |  0:12:02s\n",
      "epoch 51 | loss: 0.83701 |  0:12:16s\n",
      "epoch 52 | loss: 0.83493 |  0:12:30s\n",
      "epoch 53 | loss: 0.83412 |  0:12:42s\n",
      "epoch 54 | loss: 0.83297 |  0:12:54s\n",
      "epoch 55 | loss: 0.83282 |  0:13:08s\n",
      "epoch 56 | loss: 0.83117 |  0:13:21s\n",
      "epoch 57 | loss: 0.82904 |  0:13:35s\n",
      "epoch 58 | loss: 0.82534 |  0:13:49s\n",
      "epoch 59 | loss: 0.82282 |  0:14:03s\n",
      "epoch 60 | loss: 0.82058 |  0:14:18s\n",
      "epoch 61 | loss: 0.8198  |  0:14:35s\n",
      "epoch 62 | loss: 0.82045 |  0:14:49s\n",
      "epoch 63 | loss: 0.81917 |  0:15:04s\n",
      "epoch 64 | loss: 0.81971 |  0:15:19s\n",
      "epoch 65 | loss: 0.81736 |  0:15:31s\n",
      "epoch 66 | loss: 0.81658 |  0:15:45s\n",
      "epoch 67 | loss: 0.81672 |  0:15:59s\n",
      "epoch 68 | loss: 0.81507 |  0:16:12s\n",
      "epoch 69 | loss: 0.81458 |  0:16:28s\n",
      "epoch 70 | loss: 0.81635 |  0:16:41s\n",
      "epoch 71 | loss: 0.81494 |  0:16:54s\n",
      "epoch 72 | loss: 0.81261 |  0:17:07s\n",
      "epoch 73 | loss: 0.80735 |  0:17:20s\n",
      "epoch 74 | loss: 0.80323 |  0:17:34s\n",
      "epoch 75 | loss: 0.79621 |  0:17:52s\n",
      "epoch 76 | loss: 0.79103 |  0:18:05s\n",
      "epoch 77 | loss: 0.78183 |  0:18:18s\n",
      "epoch 78 | loss: 0.77533 |  0:18:31s\n",
      "epoch 79 | loss: 0.76823 |  0:18:45s\n",
      "epoch 80 | loss: 0.75875 |  0:18:59s\n",
      "epoch 81 | loss: 0.74921 |  0:19:12s\n",
      "epoch 82 | loss: 0.7366  |  0:19:26s\n",
      "epoch 83 | loss: 0.72139 |  0:19:39s\n",
      "epoch 84 | loss: 0.70298 |  0:19:53s\n",
      "epoch 85 | loss: 0.68369 |  0:20:07s\n",
      "epoch 86 | loss: 0.66276 |  0:20:21s\n",
      "epoch 87 | loss: 0.6427  |  0:20:36s\n",
      "epoch 88 | loss: 0.62297 |  0:20:49s\n",
      "epoch 89 | loss: 0.60108 |  0:21:03s\n"
     ]
    }
   ],
   "source": [
    "# pretrain model\n",
    "unsupervised_model = TabNetPretrainer(\n",
    "    cat_idxs=cat_col_idx,\n",
    "    cat_dims=cat_col_dims,\n",
    "    cat_emb_dim=[int(round(np.sqrt(i)/4,0))+1 for i in cat_col_dims],\n",
    "    optimizer_fn=torch.optim.Adam,\n",
    "    optimizer_params=dict(lr=5*1e-3),\n",
    "    scheduler_params={'is_batch_level': True, 'T_0':10, 'T_mult':2, 'eta_min': 0.001},\n",
    "    scheduler_fn=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts,\n",
    "    mask_type='entmax'\n",
    ")\n",
    "\n",
    "unsupervised_model.fit(\n",
    "    X_train=x_sme,\n",
    "    max_epochs=90,\n",
    "    drop_last=False,\n",
    "    pretraining_ratio=0.6, #0.5\n",
    ")\n",
    "\n",
    "reconstructed_X, embedded_X = unsupervised_model.predict(x_sme)\n",
    "assert(reconstructed_X.shape == embedded_X.shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device used : cpu\n"
     ]
    }
   ],
   "source": [
    "model = TabNetClassifier(\n",
    "    cat_idxs=cat_col_idx,\n",
    "    cat_dims=cat_col_dims,\n",
    "    cat_emb_dim=[int(round(np.sqrt(i)/4,0))+1 for i in cat_col_dims],\n",
    "    optimizer_fn=torch.optim.Adam,\n",
    "    optimizer_params=dict(lr=1e-3),\n",
    "    scheduler_params={'is_batch_level': True, 'T_0':10, 'T_mult':2, 'eta_min': 0.001},\n",
    "    scheduler_fn=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts,\n",
    "    mask_type='sparsemax',\n",
    "    gamma=1.3,\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading weights from unsupervised pretraining\n",
      "epoch 0  | loss: 8.20009 | train_balanced_accuracy: 0.53951 | train_accuracy: 0.48194 |  0:00:13s\n",
      "epoch 1  | loss: 0.95942 | train_balanced_accuracy: 0.77918 | train_accuracy: 0.79929 |  0:00:26s\n",
      "epoch 2  | loss: 0.5735  | train_balanced_accuracy: 0.80897 | train_accuracy: 0.82938 |  0:00:39s\n",
      "epoch 3  | loss: 0.51206 | train_balanced_accuracy: 0.82426 | train_accuracy: 0.84347 |  0:00:52s\n",
      "epoch 4  | loss: 0.47766 | train_balanced_accuracy: 0.83502 | train_accuracy: 0.84821 |  0:01:06s\n",
      "epoch 5  | loss: 0.45106 | train_balanced_accuracy: 0.84558 | train_accuracy: 0.85871 |  0:01:20s\n",
      "epoch 6  | loss: 0.4212  | train_balanced_accuracy: 0.86022 | train_accuracy: 0.87141 |  0:01:33s\n",
      "epoch 7  | loss: 0.39833 | train_balanced_accuracy: 0.87033 | train_accuracy: 0.87577 |  0:01:46s\n",
      "epoch 8  | loss: 0.37164 | train_balanced_accuracy: 0.87722 | train_accuracy: 0.88573 |  0:02:00s\n",
      "epoch 9  | loss: 0.35253 | train_balanced_accuracy: 0.88821 | train_accuracy: 0.8944  |  0:02:13s\n",
      "epoch 10 | loss: 0.32673 | train_balanced_accuracy: 0.90086 | train_accuracy: 0.90419 |  0:02:26s\n",
      "epoch 11 | loss: 0.30457 | train_balanced_accuracy: 0.90973 | train_accuracy: 0.91149 |  0:02:39s\n",
      "epoch 12 | loss: 0.28434 | train_balanced_accuracy: 0.91477 | train_accuracy: 0.91627 |  0:02:53s\n",
      "epoch 13 | loss: 0.26511 | train_balanced_accuracy: 0.91924 | train_accuracy: 0.92035 |  0:03:06s\n",
      "epoch 14 | loss: 0.24584 | train_balanced_accuracy: 0.92685 | train_accuracy: 0.92793 |  0:03:19s\n",
      "epoch 15 | loss: 0.23308 | train_balanced_accuracy: 0.93087 | train_accuracy: 0.93202 |  0:03:33s\n",
      "epoch 16 | loss: 0.22178 | train_balanced_accuracy: 0.93625 | train_accuracy: 0.93704 |  0:03:46s\n",
      "epoch 17 | loss: 0.21366 | train_balanced_accuracy: 0.93976 | train_accuracy: 0.93969 |  0:04:00s\n",
      "epoch 18 | loss: 0.19608 | train_balanced_accuracy: 0.94304 | train_accuracy: 0.94145 |  0:04:13s\n",
      "epoch 19 | loss: 0.18732 | train_balanced_accuracy: 0.94595 | train_accuracy: 0.94538 |  0:04:26s\n",
      "epoch 20 | loss: 0.17723 | train_balanced_accuracy: 0.94825 | train_accuracy: 0.94894 |  0:04:38s\n",
      "epoch 21 | loss: 0.16518 | train_balanced_accuracy: 0.95226 | train_accuracy: 0.95142 |  0:04:49s\n",
      "epoch 22 | loss: 0.15866 | train_balanced_accuracy: 0.95349 | train_accuracy: 0.95299 |  0:04:59s\n",
      "epoch 23 | loss: 0.15259 | train_balanced_accuracy: 0.95583 | train_accuracy: 0.95624 |  0:05:10s\n",
      "epoch 24 | loss: 0.14819 | train_balanced_accuracy: 0.9589  | train_accuracy: 0.95798 |  0:05:23s\n",
      "epoch 25 | loss: 0.14277 | train_balanced_accuracy: 0.96092 | train_accuracy: 0.96007 |  0:05:36s\n",
      "epoch 26 | loss: 0.13862 | train_balanced_accuracy: 0.96139 | train_accuracy: 0.9603  |  0:05:49s\n",
      "epoch 27 | loss: 0.13489 | train_balanced_accuracy: 0.96243 | train_accuracy: 0.96143 |  0:06:02s\n",
      "epoch 28 | loss: 0.13307 | train_balanced_accuracy: 0.96412 | train_accuracy: 0.96329 |  0:06:16s\n",
      "epoch 29 | loss: 0.12669 | train_balanced_accuracy: 0.96517 | train_accuracy: 0.96347 |  0:06:30s\n",
      "epoch 30 | loss: 0.12081 | train_balanced_accuracy: 0.96649 | train_accuracy: 0.9657  |  0:06:43s\n",
      "epoch 31 | loss: 0.11705 | train_balanced_accuracy: 0.96711 | train_accuracy: 0.96578 |  0:06:57s\n",
      "epoch 32 | loss: 0.11498 | train_balanced_accuracy: 0.96953 | train_accuracy: 0.96878 |  0:07:09s\n",
      "epoch 33 | loss: 0.11237 | train_balanced_accuracy: 0.97077 | train_accuracy: 0.96969 |  0:07:23s\n",
      "epoch 34 | loss: 0.10982 | train_balanced_accuracy: 0.9708  | train_accuracy: 0.96963 |  0:07:36s\n",
      "epoch 35 | loss: 0.10591 | train_balanced_accuracy: 0.972   | train_accuracy: 0.97058 |  0:07:49s\n",
      "epoch 36 | loss: 0.10298 | train_balanced_accuracy: 0.9716  | train_accuracy: 0.97091 |  0:08:04s\n",
      "epoch 37 | loss: 0.09756 | train_balanced_accuracy: 0.97275 | train_accuracy: 0.97188 |  0:08:17s\n",
      "epoch 38 | loss: 0.09625 | train_balanced_accuracy: 0.97374 | train_accuracy: 0.97273 |  0:08:30s\n",
      "epoch 39 | loss: 0.09534 | train_balanced_accuracy: 0.97476 | train_accuracy: 0.97399 |  0:08:43s\n",
      "epoch 40 | loss: 0.0898  | train_balanced_accuracy: 0.97585 | train_accuracy: 0.97458 |  0:08:57s\n",
      "epoch 41 | loss: 0.0905  | train_balanced_accuracy: 0.97593 | train_accuracy: 0.97514 |  0:09:10s\n",
      "epoch 42 | loss: 0.08825 | train_balanced_accuracy: 0.97756 | train_accuracy: 0.97644 |  0:09:23s\n",
      "epoch 43 | loss: 0.08672 | train_balanced_accuracy: 0.97773 | train_accuracy: 0.97665 |  0:09:36s\n",
      "epoch 44 | loss: 0.08169 | train_balanced_accuracy: 0.97895 | train_accuracy: 0.97773 |  0:09:50s\n",
      "epoch 45 | loss: 0.08097 | train_balanced_accuracy: 0.97885 | train_accuracy: 0.97739 |  0:10:04s\n",
      "epoch 46 | loss: 0.08048 | train_balanced_accuracy: 0.98044 | train_accuracy: 0.97924 |  0:10:17s\n",
      "epoch 47 | loss: 0.07859 | train_balanced_accuracy: 0.98026 | train_accuracy: 0.9787  |  0:10:32s\n",
      "epoch 48 | loss: 0.07127 | train_balanced_accuracy: 0.98128 | train_accuracy: 0.97995 |  0:10:50s\n",
      "epoch 49 | loss: 0.07268 | train_balanced_accuracy: 0.98026 | train_accuracy: 0.98003 |  0:11:04s\n",
      "Stop training because you reached max_epochs = 50 with best_epoch = 49 and best_train_accuracy = 0.98003\n",
      "Best weights from best epoch are automatically used!\n"
     ]
    }
   ],
   "source": [
    "model.fit(\n",
    "    X_train=x_sme,\n",
    "    y_train=y_sme,\n",
    "    eval_set=[(x_sme, y_sme)],\n",
    "    eval_name=['train'],\n",
    "    eval_metric=['balanced_accuracy', 'accuracy'],\n",
    "    max_epochs=50,\n",
    "    patience=5,\n",
    "    weights=1,  # 0: no, 1: balanced, dict: customized\n",
    "    batch_size=512,\n",
    "    virtual_batch_size=128,\n",
    "    num_workers=0,\n",
    "    drop_last=False,\n",
    "    from_unsupervised=unsupervised_model,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Result"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Customer_ID :  0.44\n",
      "Month :  0.098\n",
      "Age :  0.0\n",
      "Monthly_Inhand_Salary :  0.002\n",
      "Num_Bank_Accounts :  0.031\n",
      "Num_Credit_Card :  0.036\n",
      "Interest_Rate :  0.036\n",
      "Num_of_Loan :  0.021\n",
      "Delay_from_due_date :  0.043\n",
      "Num_of_Delayed_Payment :  0.003\n",
      "Changed_Credit_Limit :  0.003\n",
      "Num_Credit_Inquiries :  0.024\n",
      "Credit_Mix :  0.065\n",
      "Outstanding_Debt :  0.055\n",
      "Credit_Utilization_Ratio :  0.003\n",
      "Credit_History_Age :  0.014\n",
      "Payment_of_Min_Amount :  0.011\n",
      "Total_EMI_per_month :  0.019\n",
      "Amount_invested_monthly :  0.014\n",
      "Payment_Behaviour :  0.044\n",
      "Monthly_Balance :  0.036\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(all_col_list)):\n",
    "    print(all_col_list[i], ': ', model.feature_importances_.round(3)[i])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.90      0.82     21782\n",
      "           1       0.95      0.71      0.81     40214\n",
      "           2       0.65      0.94      0.77     13004\n",
      "\n",
      "    accuracy                           0.80     75000\n",
      "   macro avg       0.78      0.85      0.80     75000\n",
      "weighted avg       0.84      0.80      0.81     75000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_true=y_train, y_pred=model.predict(x_train)))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "# f1_score(y_train, (model.predict(x_train)))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "outputs": [],
   "source": [
    "predicted = model.predict(x_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6480747897150249\n",
      "0.64336\n"
     ]
    }
   ],
   "source": [
    "print(f1_score(y_test, predicted, average='weighted'))\n",
    "print(accuracy_score(y_test, predicted))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.71      0.69      7216\n",
      "           1       0.77      0.57      0.65     12960\n",
      "           2       0.46      0.74      0.57      4824\n",
      "\n",
      "    accuracy                           0.64     25000\n",
      "   macro avg       0.63      0.67      0.64     25000\n",
      "weighted avg       0.68      0.64      0.65     25000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, predicted))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5148 1064 1004]\n",
      " [2403 7353 3204]\n",
      " [ 108 1133 3583]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, predicted))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "class weight 부여 후 0과 2클래스에 대해 더 많이 맞췄음."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 1152x720 with 3 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "explain_matrix, masks = model.explain(x_test)\n",
    "\n",
    "fig, axs = plt.subplots(1, 3, figsize=(16,10))\n",
    "for i in range(3):\n",
    "    axs[i].imshow(masks[i][:50])\n",
    "    axs[i].set_title(f\"mask {i}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Without Class_weights"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading weights from unsupervised pretraining\n",
      "epoch 0  | loss: 1.65824 | train_balanced_accuracy: 0.72305 | train_accuracy: 0.7804  |  0:00:15s\n",
      "epoch 1  | loss: 0.53688 | train_balanced_accuracy: 0.80609 | train_accuracy: 0.83844 |  0:00:28s\n",
      "epoch 2  | loss: 0.48049 | train_balanced_accuracy: 0.81825 | train_accuracy: 0.84699 |  0:00:43s\n",
      "epoch 3  | loss: 0.45191 | train_balanced_accuracy: 0.82259 | train_accuracy: 0.85121 |  0:00:56s\n",
      "epoch 4  | loss: 0.43172 | train_balanced_accuracy: 0.82547 | train_accuracy: 0.85588 |  0:01:09s\n",
      "epoch 5  | loss: 0.41822 | train_balanced_accuracy: 0.83181 | train_accuracy: 0.86069 |  0:01:23s\n",
      "epoch 6  | loss: 0.40101 | train_balanced_accuracy: 0.84289 | train_accuracy: 0.86568 |  0:01:37s\n",
      "epoch 7  | loss: 0.38077 | train_balanced_accuracy: 0.8509  | train_accuracy: 0.87469 |  0:01:52s\n",
      "epoch 8  | loss: 0.36028 | train_balanced_accuracy: 0.86479 | train_accuracy: 0.88255 |  0:02:06s\n",
      "epoch 9  | loss: 0.33792 | train_balanced_accuracy: 0.87432 | train_accuracy: 0.89253 |  0:02:19s\n",
      "epoch 10 | loss: 0.31057 | train_balanced_accuracy: 0.88642 | train_accuracy: 0.90434 |  0:02:33s\n",
      "epoch 11 | loss: 0.28915 | train_balanced_accuracy: 0.89792 | train_accuracy: 0.9119  |  0:02:47s\n",
      "epoch 12 | loss: 0.26756 | train_balanced_accuracy: 0.90807 | train_accuracy: 0.92002 |  0:03:01s\n",
      "epoch 13 | loss: 0.24838 | train_balanced_accuracy: 0.91116 | train_accuracy: 0.92524 |  0:03:15s\n",
      "epoch 14 | loss: 0.23228 | train_balanced_accuracy: 0.92209 | train_accuracy: 0.9331  |  0:03:28s\n",
      "epoch 15 | loss: 0.216   | train_balanced_accuracy: 0.92741 | train_accuracy: 0.93797 |  0:03:42s\n",
      "epoch 16 | loss: 0.20354 | train_balanced_accuracy: 0.93471 | train_accuracy: 0.94271 |  0:03:56s\n",
      "epoch 17 | loss: 0.18916 | train_balanced_accuracy: 0.93786 | train_accuracy: 0.94534 |  0:04:10s\n",
      "epoch 18 | loss: 0.17863 | train_balanced_accuracy: 0.94662 | train_accuracy: 0.95292 |  0:04:23s\n",
      "epoch 19 | loss: 0.16667 | train_balanced_accuracy: 0.95294 | train_accuracy: 0.95647 |  0:04:37s\n",
      "epoch 20 | loss: 0.1589  | train_balanced_accuracy: 0.95327 | train_accuracy: 0.95873 |  0:04:51s\n",
      "epoch 21 | loss: 0.14882 | train_balanced_accuracy: 0.95903 | train_accuracy: 0.96241 |  0:05:05s\n",
      "epoch 22 | loss: 0.14075 | train_balanced_accuracy: 0.96107 | train_accuracy: 0.96473 |  0:05:18s\n",
      "epoch 23 | loss: 0.13278 | train_balanced_accuracy: 0.96315 | train_accuracy: 0.96688 |  0:05:33s\n",
      "epoch 24 | loss: 0.12771 | train_balanced_accuracy: 0.96665 | train_accuracy: 0.96896 |  0:05:46s\n",
      "epoch 25 | loss: 0.12078 | train_balanced_accuracy: 0.96803 | train_accuracy: 0.97032 |  0:06:02s\n",
      "epoch 26 | loss: 0.11543 | train_balanced_accuracy: 0.96896 | train_accuracy: 0.9725  |  0:06:17s\n",
      "epoch 27 | loss: 0.11195 | train_balanced_accuracy: 0.97172 | train_accuracy: 0.97412 |  0:06:30s\n",
      "epoch 28 | loss: 0.10639 | train_balanced_accuracy: 0.97342 | train_accuracy: 0.97581 |  0:06:43s\n",
      "epoch 29 | loss: 0.10162 | train_balanced_accuracy: 0.97294 | train_accuracy: 0.97649 |  0:06:56s\n",
      "epoch 30 | loss: 0.09737 | train_balanced_accuracy: 0.97621 | train_accuracy: 0.97851 |  0:07:09s\n",
      "epoch 31 | loss: 0.09401 | train_balanced_accuracy: 0.9765  | train_accuracy: 0.97925 |  0:07:25s\n",
      "epoch 32 | loss: 0.08959 | train_balanced_accuracy: 0.97839 | train_accuracy: 0.97967 |  0:07:38s\n",
      "epoch 33 | loss: 0.08633 | train_balanced_accuracy: 0.97922 | train_accuracy: 0.98115 |  0:07:52s\n",
      "epoch 34 | loss: 0.08376 | train_balanced_accuracy: 0.97885 | train_accuracy: 0.98106 |  0:08:06s\n",
      "epoch 35 | loss: 0.07961 | train_balanced_accuracy: 0.98167 | train_accuracy: 0.98293 |  0:08:20s\n",
      "epoch 36 | loss: 0.07808 | train_balanced_accuracy: 0.98234 | train_accuracy: 0.98324 |  0:08:34s\n",
      "epoch 37 | loss: 0.07446 | train_balanced_accuracy: 0.98255 | train_accuracy: 0.98376 |  0:08:47s\n",
      "epoch 38 | loss: 0.07431 | train_balanced_accuracy: 0.98287 | train_accuracy: 0.98442 |  0:09:00s\n",
      "epoch 39 | loss: 0.07172 | train_balanced_accuracy: 0.98387 | train_accuracy: 0.98557 |  0:09:14s\n",
      "epoch 40 | loss: 0.0693  | train_balanced_accuracy: 0.98511 | train_accuracy: 0.98616 |  0:09:30s\n",
      "epoch 41 | loss: 0.06698 | train_balanced_accuracy: 0.98421 | train_accuracy: 0.98619 |  0:09:44s\n",
      "epoch 42 | loss: 0.06419 | train_balanced_accuracy: 0.98632 | train_accuracy: 0.98759 |  0:09:57s\n",
      "epoch 43 | loss: 0.06152 | train_balanced_accuracy: 0.98664 | train_accuracy: 0.98764 |  0:10:14s\n",
      "epoch 44 | loss: 0.06036 | train_balanced_accuracy: 0.987   | train_accuracy: 0.98847 |  0:10:29s\n",
      "epoch 45 | loss: 0.05877 | train_balanced_accuracy: 0.98768 | train_accuracy: 0.98842 |  0:10:45s\n",
      "epoch 46 | loss: 0.05704 | train_balanced_accuracy: 0.98835 | train_accuracy: 0.98925 |  0:11:00s\n",
      "epoch 47 | loss: 0.05532 | train_balanced_accuracy: 0.98865 | train_accuracy: 0.98959 |  0:11:16s\n",
      "epoch 48 | loss: 0.05434 | train_balanced_accuracy: 0.989   | train_accuracy: 0.99007 |  0:11:30s\n",
      "epoch 49 | loss: 0.05228 | train_balanced_accuracy: 0.98908 | train_accuracy: 0.99029 |  0:11:46s\n",
      "Stop training because you reached max_epochs = 50 with best_epoch = 49 and best_train_accuracy = 0.99029\n",
      "Best weights from best epoch are automatically used!\n"
     ]
    }
   ],
   "source": [
    "model.fit(\n",
    "    X_train=x_sme,\n",
    "    y_train=y_sme,\n",
    "    eval_set=[(x_sme, y_sme)],\n",
    "    eval_name=['train'],\n",
    "    eval_metric=['balanced_accuracy', 'accuracy'],\n",
    "    max_epochs=50,\n",
    "    patience=5,\n",
    "    weights=0,  # 0: no, 1: balanced, dict: customized\n",
    "    batch_size=512,\n",
    "    virtual_batch_size=128,\n",
    "    num_workers=0,\n",
    "    drop_last=False,\n",
    "    from_unsupervised=unsupervised_model,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Result"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Customer_ID :  0.564\n",
      "Month :  0.066\n",
      "Age :  0.0\n",
      "Monthly_Inhand_Salary :  0.0\n",
      "Num_Bank_Accounts :  0.019\n",
      "Num_Credit_Card :  0.04\n",
      "Interest_Rate :  0.016\n",
      "Num_of_Loan :  0.014\n",
      "Delay_from_due_date :  0.041\n",
      "Num_of_Delayed_Payment :  0.0\n",
      "Changed_Credit_Limit :  0.007\n",
      "Num_Credit_Inquiries :  0.017\n",
      "Credit_Mix :  0.068\n",
      "Outstanding_Debt :  0.031\n",
      "Credit_Utilization_Ratio :  0.0\n",
      "Credit_History_Age :  0.018\n",
      "Payment_of_Min_Amount :  0.016\n",
      "Total_EMI_per_month :  0.004\n",
      "Amount_invested_monthly :  0.001\n",
      "Payment_Behaviour :  0.048\n",
      "Monthly_Balance :  0.028\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(all_col_list)):\n",
    "    print(all_col_list[i], ': ', model.feature_importances_.round(3)[i])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.92      0.83     21782\n",
      "           1       0.95      0.72      0.82     40214\n",
      "           2       0.67      0.95      0.79     13004\n",
      "\n",
      "    accuracy                           0.81     75000\n",
      "   macro avg       0.79      0.86      0.81     75000\n",
      "weighted avg       0.85      0.81      0.82     75000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_true=y_train, y_pred=model.predict(x_train)))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "outputs": [],
   "source": [
    "# f1_score(y_train, (model.predict(x_train)))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "outputs": [],
   "source": [
    "predicted = model.predict(x_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6586681611336666\n",
      "0.65592\n"
     ]
    }
   ],
   "source": [
    "print(f1_score(y_test, predicted, average='weighted'))\n",
    "print(accuracy_score(y_test, predicted))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.70      0.69      7216\n",
      "           1       0.75      0.60      0.66     12960\n",
      "           2       0.51      0.74      0.60      4824\n",
      "\n",
      "    accuracy                           0.66     25000\n",
      "   macro avg       0.64      0.68      0.65     25000\n",
      "weighted avg       0.68      0.66      0.66     25000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, predicted))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5058 1464  694]\n",
      " [2388 7753 2819]\n",
      " [  95 1142 3587]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, predicted))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 1152x720 with 3 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "explain_matrix, masks = model.explain(x_test)\n",
    "\n",
    "fig, axs = plt.subplots(1, 3, figsize=(16,10))\n",
    "for i in range(3):\n",
    "    axs[i].imshow(masks[i][:50])\n",
    "    axs[i].set_title(f\"mask {i}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "outputs": [
    {
     "data": {
      "text/plain": "1    40214\n0    21782\n2    13004\ndtype: int64"
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(y_train).value_counts()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "위에서는 ENN으로 다수 데이터를 약 2만3천여개 줄였음. 정보의 유실이 많은 상태였음. 이번엔 유실을 완화시켜보도록 함"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "outputs": [],
   "source": [
    "enn = EditedNearestNeighbours(kind_sel='mode', n_jobs=-1) # less conservative"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before SMOTE ENN....\n",
      "The shape of your X data:  (75000, 21)\n",
      "The shape of your y data:  (75000,)\n",
      "Label Counts : \n",
      " 0    21782\n",
      "1    40214\n",
      "2    13004\n",
      "dtype: int64\n",
      "\n",
      "\n",
      "After SMOTE ENN Applied....\n",
      "The shape of your X_SME data:  (102463, 21)\n",
      "The shape of your y_SME data:  (102463,)\n",
      "Label Counts : \n",
      " 0    40214\n",
      "1    24534\n",
      "2    37715\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "x_sme, y_sme = sampling_smote_enn(x_train, y_train, smote=smote, enn=enn)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device used : cpu\n",
      "No early stopping will be performed, last training weights will be used.\n",
      "epoch 0  | loss: 3.91526 |  0:00:23s\n",
      "epoch 1  | loss: 1.9489  |  0:00:44s\n",
      "epoch 2  | loss: 1.42341 |  0:01:06s\n",
      "epoch 3  | loss: 1.1632  |  0:01:27s\n",
      "epoch 4  | loss: 1.05293 |  0:01:48s\n",
      "epoch 5  | loss: 1.02697 |  0:02:11s\n",
      "epoch 6  | loss: 1.00979 |  0:02:30s\n",
      "epoch 7  | loss: 0.98161 |  0:02:46s\n",
      "epoch 8  | loss: 0.96538 |  0:03:05s\n",
      "epoch 9  | loss: 0.95332 |  0:03:22s\n",
      "epoch 10 | loss: 0.94659 |  0:03:41s\n",
      "epoch 11 | loss: 0.94321 |  0:03:59s\n",
      "epoch 12 | loss: 0.94056 |  0:04:17s\n",
      "epoch 13 | loss: 0.93409 |  0:04:36s\n",
      "epoch 14 | loss: 0.92628 |  0:04:55s\n",
      "epoch 15 | loss: 0.91971 |  0:05:13s\n",
      "epoch 16 | loss: 0.9158  |  0:05:32s\n",
      "epoch 17 | loss: 0.90947 |  0:05:50s\n",
      "epoch 18 | loss: 0.90306 |  0:06:08s\n",
      "epoch 19 | loss: 0.8995  |  0:06:26s\n",
      "epoch 20 | loss: 0.89703 |  0:06:45s\n",
      "epoch 21 | loss: 0.89356 |  0:07:03s\n",
      "epoch 22 | loss: 0.89233 |  0:07:21s\n",
      "epoch 23 | loss: 0.89017 |  0:07:39s\n",
      "epoch 24 | loss: 0.88962 |  0:07:57s\n",
      "epoch 25 | loss: 0.88819 |  0:08:15s\n",
      "epoch 26 | loss: 0.88429 |  0:08:37s\n",
      "epoch 27 | loss: 0.87948 |  0:08:57s\n",
      "epoch 28 | loss: 0.87554 |  0:09:15s\n",
      "epoch 29 | loss: 0.87276 |  0:09:35s\n",
      "epoch 30 | loss: 0.87028 |  0:09:54s\n",
      "epoch 31 | loss: 0.86803 |  0:10:35s\n",
      "epoch 32 | loss: 0.865   |  0:11:01s\n",
      "epoch 33 | loss: 0.86175 |  0:11:20s\n",
      "epoch 34 | loss: 0.85921 |  0:11:39s\n",
      "epoch 35 | loss: 0.85675 |  0:11:56s\n",
      "epoch 36 | loss: 0.85481 |  0:12:15s\n",
      "epoch 37 | loss: 0.85342 |  0:12:34s\n",
      "epoch 38 | loss: 0.8534  |  0:12:52s\n",
      "epoch 39 | loss: 0.85196 |  0:13:11s\n",
      "epoch 40 | loss: 0.85087 |  0:13:29s\n",
      "epoch 41 | loss: 0.85102 |  0:13:47s\n",
      "epoch 42 | loss: 0.84993 |  0:14:05s\n",
      "epoch 43 | loss: 0.84948 |  0:14:23s\n",
      "epoch 44 | loss: 0.84728 |  0:14:41s\n",
      "epoch 45 | loss: 0.84656 |  0:15:00s\n",
      "epoch 46 | loss: 0.84577 |  0:15:18s\n",
      "epoch 47 | loss: 0.84576 |  0:15:36s\n",
      "epoch 48 | loss: 0.84493 |  0:15:54s\n",
      "epoch 49 | loss: 0.84511 |  0:16:12s\n",
      "epoch 50 | loss: 0.84506 |  0:16:31s\n",
      "epoch 51 | loss: 0.84566 |  0:16:50s\n",
      "epoch 52 | loss: 0.84071 |  0:17:10s\n",
      "epoch 53 | loss: 0.83846 |  0:17:27s\n",
      "epoch 54 | loss: 0.83415 |  0:17:45s\n",
      "epoch 55 | loss: 0.83072 |  0:18:03s\n",
      "epoch 56 | loss: 0.82843 |  0:18:21s\n",
      "epoch 57 | loss: 0.82565 |  0:18:39s\n",
      "epoch 58 | loss: 0.82262 |  0:18:58s\n",
      "epoch 59 | loss: 0.81753 |  0:19:16s\n",
      "epoch 60 | loss: 0.81296 |  0:19:34s\n",
      "epoch 61 | loss: 0.80797 |  0:19:51s\n",
      "epoch 62 | loss: 0.80217 |  0:20:10s\n",
      "epoch 63 | loss: 0.79546 |  0:20:28s\n",
      "epoch 64 | loss: 0.78846 |  0:20:46s\n",
      "epoch 65 | loss: 0.78066 |  0:21:03s\n",
      "epoch 66 | loss: 0.77006 |  0:21:21s\n",
      "epoch 67 | loss: 0.75572 |  0:21:39s\n",
      "epoch 68 | loss: 0.73331 |  0:21:58s\n",
      "epoch 69 | loss: 0.70822 |  0:22:16s\n",
      "epoch 70 | loss: 0.68177 |  0:22:33s\n",
      "epoch 71 | loss: 0.65817 |  0:22:51s\n",
      "epoch 72 | loss: 0.63507 |  0:23:10s\n",
      "epoch 73 | loss: 0.61274 |  0:23:47s\n",
      "epoch 74 | loss: 0.59159 |  0:24:58s\n",
      "epoch 75 | loss: 0.57224 |  0:25:46s\n",
      "epoch 76 | loss: 0.55313 |  0:26:20s\n",
      "epoch 77 | loss: 0.53615 |  0:26:46s\n",
      "epoch 78 | loss: 0.52112 |  0:27:04s\n",
      "epoch 79 | loss: 0.50478 |  0:27:23s\n",
      "epoch 80 | loss: 0.49188 |  0:27:41s\n",
      "epoch 81 | loss: 0.48052 |  0:27:59s\n",
      "epoch 82 | loss: 0.46879 |  0:28:19s\n",
      "epoch 83 | loss: 0.45836 |  0:28:38s\n",
      "epoch 84 | loss: 0.44854 |  0:28:56s\n",
      "epoch 85 | loss: 0.43912 |  0:29:15s\n",
      "epoch 86 | loss: 0.43229 |  0:29:33s\n",
      "epoch 87 | loss: 0.42474 |  0:29:51s\n",
      "epoch 88 | loss: 0.41754 |  0:30:08s\n",
      "epoch 89 | loss: 0.41105 |  0:30:29s\n"
     ]
    }
   ],
   "source": [
    "# pretrain model\n",
    "unsupervised_model = TabNetPretrainer(\n",
    "    cat_idxs=cat_col_idx,\n",
    "    cat_dims=cat_col_dims,\n",
    "    cat_emb_dim=[int(round(np.sqrt(i)/4,0))+1 for i in cat_col_dims],\n",
    "    optimizer_fn=torch.optim.Adam,\n",
    "    optimizer_params=dict(lr=5*1e-3),\n",
    "    scheduler_params={'is_batch_level': True, 'T_0':10, 'T_mult':2, 'eta_min': 0.001},\n",
    "    scheduler_fn=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts,\n",
    "    mask_type='entmax'\n",
    ")\n",
    "\n",
    "unsupervised_model.fit(\n",
    "    X_train=x_sme,\n",
    "    max_epochs=90,\n",
    "    drop_last=False,\n",
    "    pretraining_ratio=0.6, #0.5\n",
    ")\n",
    "\n",
    "reconstructed_X, embedded_X = unsupervised_model.predict(x_sme)\n",
    "assert(reconstructed_X.shape == embedded_X.shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device used : cpu\n"
     ]
    }
   ],
   "source": [
    "model = TabNetClassifier(\n",
    "    cat_idxs=cat_col_idx,\n",
    "    cat_dims=cat_col_dims,\n",
    "    cat_emb_dim=[int(round(np.sqrt(i)/4,0))+1 for i in cat_col_dims],\n",
    "    optimizer_fn=torch.optim.Adam,\n",
    "    optimizer_params=dict(lr=1e-3),\n",
    "    scheduler_params={'is_batch_level': True, 'T_0':10, 'T_mult':2, 'eta_min': 0.001},\n",
    "    scheduler_fn=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts,\n",
    "    mask_type='sparsemax',\n",
    "    gamma=1.3,\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading weights from unsupervised pretraining\n",
      "epoch 0  | loss: 7.49411 | train_balanced_accuracy: 0.70359 | train_accuracy: 0.7331  |  0:00:16s\n",
      "epoch 1  | loss: 0.62062 | train_balanced_accuracy: 0.77657 | train_accuracy: 0.7932  |  0:00:36s\n",
      "epoch 2  | loss: 0.54972 | train_balanced_accuracy: 0.79289 | train_accuracy: 0.80897 |  0:00:53s\n",
      "epoch 3  | loss: 0.51511 | train_balanced_accuracy: 0.81757 | train_accuracy: 0.82387 |  0:01:11s\n",
      "epoch 4  | loss: 0.47502 | train_balanced_accuracy: 0.8397  | train_accuracy: 0.84361 |  0:01:29s\n",
      "epoch 5  | loss: 0.4271  | train_balanced_accuracy: 0.86141 | train_accuracy: 0.86435 |  0:01:46s\n",
      "epoch 6  | loss: 0.38243 | train_balanced_accuracy: 0.87318 | train_accuracy: 0.87884 |  0:02:04s\n",
      "epoch 7  | loss: 0.3388  | train_balanced_accuracy: 0.8939  | train_accuracy: 0.89846 |  0:02:21s\n",
      "epoch 8  | loss: 0.30274 | train_balanced_accuracy: 0.90866 | train_accuracy: 0.91064 |  0:02:40s\n",
      "epoch 9  | loss: 0.27768 | train_balanced_accuracy: 0.91241 | train_accuracy: 0.91633 |  0:02:57s\n",
      "epoch 10 | loss: 0.25492 | train_balanced_accuracy: 0.92402 | train_accuracy: 0.92612 |  0:03:15s\n",
      "epoch 11 | loss: 0.23699 | train_balanced_accuracy: 0.92868 | train_accuracy: 0.93034 |  0:03:32s\n",
      "epoch 12 | loss: 0.22295 | train_balanced_accuracy: 0.93361 | train_accuracy: 0.93613 |  0:03:49s\n",
      "epoch 13 | loss: 0.20987 | train_balanced_accuracy: 0.937   | train_accuracy: 0.93824 |  0:04:07s\n",
      "epoch 14 | loss: 0.1977  | train_balanced_accuracy: 0.94183 | train_accuracy: 0.94355 |  0:04:24s\n",
      "epoch 15 | loss: 0.18763 | train_balanced_accuracy: 0.94446 | train_accuracy: 0.94665 |  0:04:41s\n",
      "epoch 16 | loss: 0.17976 | train_balanced_accuracy: 0.94608 | train_accuracy: 0.94907 |  0:04:58s\n",
      "epoch 17 | loss: 0.17335 | train_balanced_accuracy: 0.94714 | train_accuracy: 0.94922 |  0:05:15s\n",
      "epoch 18 | loss: 0.16646 | train_balanced_accuracy: 0.95093 | train_accuracy: 0.95221 |  0:05:33s\n",
      "epoch 19 | loss: 0.16102 | train_balanced_accuracy: 0.95255 | train_accuracy: 0.9544  |  0:05:56s\n",
      "epoch 20 | loss: 0.15465 | train_balanced_accuracy: 0.9546  | train_accuracy: 0.95629 |  0:06:14s\n",
      "epoch 21 | loss: 0.14975 | train_balanced_accuracy: 0.95545 | train_accuracy: 0.95848 |  0:06:32s\n",
      "epoch 22 | loss: 0.14521 | train_balanced_accuracy: 0.956   | train_accuracy: 0.95947 |  0:06:49s\n",
      "epoch 23 | loss: 0.14251 | train_balanced_accuracy: 0.9571  | train_accuracy: 0.9589  |  0:07:06s\n",
      "epoch 24 | loss: 0.13775 | train_balanced_accuracy: 0.95943 | train_accuracy: 0.96276 |  0:07:23s\n",
      "epoch 25 | loss: 0.13372 | train_balanced_accuracy: 0.95861 | train_accuracy: 0.96163 |  0:07:41s\n",
      "epoch 26 | loss: 0.12993 | train_balanced_accuracy: 0.96127 | train_accuracy: 0.96409 |  0:07:58s\n",
      "epoch 27 | loss: 0.12724 | train_balanced_accuracy: 0.96137 | train_accuracy: 0.96523 |  0:08:15s\n",
      "epoch 28 | loss: 0.12482 | train_balanced_accuracy: 0.962   | train_accuracy: 0.96429 |  0:08:32s\n",
      "epoch 29 | loss: 0.12078 | train_balanced_accuracy: 0.96405 | train_accuracy: 0.96677 |  0:08:50s\n",
      "epoch 30 | loss: 0.11837 | train_balanced_accuracy: 0.96554 | train_accuracy: 0.96853 |  0:09:08s\n",
      "epoch 31 | loss: 0.11557 | train_balanced_accuracy: 0.96514 | train_accuracy: 0.96792 |  0:09:25s\n",
      "epoch 32 | loss: 0.11452 | train_balanced_accuracy: 0.96626 | train_accuracy: 0.96928 |  0:09:43s\n",
      "epoch 33 | loss: 0.1107  | train_balanced_accuracy: 0.96726 | train_accuracy: 0.97036 |  0:10:00s\n",
      "epoch 34 | loss: 0.10798 | train_balanced_accuracy: 0.96889 | train_accuracy: 0.97131 |  0:10:18s\n",
      "epoch 35 | loss: 0.10705 | train_balanced_accuracy: 0.96835 | train_accuracy: 0.97175 |  0:10:36s\n",
      "epoch 36 | loss: 0.10363 | train_balanced_accuracy: 0.97007 | train_accuracy: 0.97184 |  0:10:53s\n",
      "epoch 37 | loss: 0.10243 | train_balanced_accuracy: 0.96932 | train_accuracy: 0.97309 |  0:11:10s\n",
      "epoch 38 | loss: 0.10049 | train_balanced_accuracy: 0.97122 | train_accuracy: 0.97418 |  0:11:29s\n",
      "epoch 39 | loss: 0.09968 | train_balanced_accuracy: 0.97102 | train_accuracy: 0.97427 |  0:11:47s\n",
      "epoch 40 | loss: 0.09648 | train_balanced_accuracy: 0.97149 | train_accuracy: 0.97504 |  0:12:09s\n",
      "epoch 41 | loss: 0.09575 | train_balanced_accuracy: 0.97315 | train_accuracy: 0.976   |  0:12:31s\n",
      "epoch 42 | loss: 0.09315 | train_balanced_accuracy: 0.9734  | train_accuracy: 0.976   |  0:12:49s\n",
      "epoch 43 | loss: 0.09113 | train_balanced_accuracy: 0.97343 | train_accuracy: 0.97585 |  0:13:08s\n",
      "epoch 44 | loss: 0.09048 | train_balanced_accuracy: 0.9732  | train_accuracy: 0.97671 |  0:13:27s\n",
      "epoch 45 | loss: 0.08959 | train_balanced_accuracy: 0.97461 | train_accuracy: 0.97781 |  0:13:46s\n",
      "epoch 46 | loss: 0.08743 | train_balanced_accuracy: 0.97487 | train_accuracy: 0.97757 |  0:14:07s\n",
      "epoch 47 | loss: 0.08545 | train_balanced_accuracy: 0.97471 | train_accuracy: 0.97766 |  0:14:26s\n",
      "epoch 48 | loss: 0.08552 | train_balanced_accuracy: 0.97539 | train_accuracy: 0.97789 |  0:14:46s\n",
      "epoch 49 | loss: 0.08547 | train_balanced_accuracy: 0.97625 | train_accuracy: 0.97937 |  0:15:06s\n",
      "Stop training because you reached max_epochs = 50 with best_epoch = 49 and best_train_accuracy = 0.97937\n",
      "Best weights from best epoch are automatically used!\n"
     ]
    }
   ],
   "source": [
    "model.fit(\n",
    "    X_train=x_sme,\n",
    "    y_train=y_sme,\n",
    "    eval_set=[(x_sme, y_sme)],\n",
    "    eval_name=['train'],\n",
    "    eval_metric=['balanced_accuracy', 'accuracy'],\n",
    "    max_epochs=50,\n",
    "    patience=5,\n",
    "    weights=0,  # 0: no, 1: balanced, dict: customized\n",
    "    batch_size=512,\n",
    "    virtual_batch_size=128,\n",
    "    num_workers=0,\n",
    "    drop_last=False,\n",
    "    from_unsupervised=unsupervised_model,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Result"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Customer_ID :  0.383\n",
      "Month :  0.025\n",
      "Age :  0.026\n",
      "Monthly_Inhand_Salary :  0.123\n",
      "Num_Bank_Accounts :  0.021\n",
      "Num_Credit_Card :  0.025\n",
      "Interest_Rate :  0.061\n",
      "Num_of_Loan :  0.034\n",
      "Delay_from_due_date :  0.085\n",
      "Num_of_Delayed_Payment :  0.025\n",
      "Changed_Credit_Limit :  0.004\n",
      "Num_Credit_Inquiries :  0.028\n",
      "Credit_Mix :  0.002\n",
      "Outstanding_Debt :  0.05\n",
      "Credit_Utilization_Ratio :  0.001\n",
      "Credit_History_Age :  0.072\n",
      "Payment_of_Min_Amount :  0.006\n",
      "Total_EMI_per_month :  0.008\n",
      "Amount_invested_monthly :  0.0\n",
      "Payment_Behaviour :  0.018\n",
      "Monthly_Balance :  0.003\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(all_col_list)):\n",
    "    print(all_col_list[i], ': ', model.feature_importances_.round(3)[i])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.99      0.89     21782\n",
      "           1       0.99      0.78      0.87     40214\n",
      "           2       0.78      0.98      0.87     13004\n",
      "\n",
      "    accuracy                           0.88     75000\n",
      "   macro avg       0.86      0.92      0.88     75000\n",
      "weighted avg       0.90      0.88      0.88     75000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_true=y_train, y_pred=model.predict(x_train)))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "outputs": [],
   "source": [
    "# f1_score(y_train, (model.predict(x_train)))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "outputs": [],
   "source": [
    "predicted = model.predict(x_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7274581696255983\n",
      "0.72888\n"
     ]
    }
   ],
   "source": [
    "print(f1_score(y_test, predicted, average='weighted'))\n",
    "print(accuracy_score(y_test, predicted))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.86      0.76      7216\n",
      "           1       0.79      0.66      0.72     12960\n",
      "           2       0.67      0.73      0.70      4824\n",
      "\n",
      "    accuracy                           0.73     25000\n",
      "   macro avg       0.72      0.75      0.73     25000\n",
      "weighted avg       0.74      0.73      0.73     25000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, predicted))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "기존 대비 0번 클래스를 더 잘맞추나, 2번 클래스에 대한 전반적인 성능은 줄었음"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6179 1006   31]\n",
      " [2736 8527 1697]\n",
      " [  56 1252 3516]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, predicted))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Scaler"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "outputs": [
    {
     "data": {
      "text/plain": "       Customer_ID  Month  Age  Occupation  Monthly_Inhand_Salary  \\\n0              576      0    3          12               7.509249   \n1              576      1    3          12               7.509249   \n2              576      2    3          12               7.509249   \n3              576      3    3          12               7.509249   \n4              576      4    3          12               7.509249   \n...            ...    ...  ...         ...                    ...   \n74995         9254      1    3           9               8.119522   \n74996         9254      2    3           9               8.119522   \n74997         9254      3    3           9               8.119522   \n74998         9254      4    3           9               8.119522   \n74999         9254      5    3           9               8.119522   \n\n       Num_Bank_Accounts  Num_Credit_Card  Interest_Rate  Num_of_Loan  \\\n0                    3.0              4.0            3.0            0   \n1                    3.0              4.0            3.0            0   \n2                    3.0              4.0            3.0            0   \n3                    3.0              4.0            3.0            0   \n4                    3.0              4.0            3.0            0   \n...                  ...              ...            ...          ...   \n74995                4.0              6.0            7.0            0   \n74996                4.0              6.0            7.0            0   \n74997                4.0              6.0            7.0            0   \n74998                4.0              6.0            7.0            0   \n74999                4.0              6.0            7.0            0   \n\n       Delay_from_due_date  ...  Credit_Mix  Outstanding_Debt  \\\n0                      3.0  ...           2         28.460148   \n1                      3.0  ...           2         28.460148   \n2                      3.0  ...           2         28.460148   \n3                      5.0  ...           2         28.460148   \n4                      6.0  ...           2         28.460148   \n...                    ...  ...         ...               ...   \n74995                 23.0  ...           2         22.413835   \n74996                 20.0  ...           2         22.413835   \n74997                 23.0  ...           2         22.413835   \n74998                 18.0  ...           2         22.413835   \n74999                 27.0  ...           2         22.413835   \n\n       Credit_Utilization_Ratio  Credit_History_Age  Payment_of_Min_Amount  \\\n0                     26.822620                   1                      1   \n1                     31.944960                   1                      1   \n2                     28.609352                   1                      1   \n3                     31.377862                   1                      1   \n4                     24.797347                   1                      1   \n...                         ...                 ...                    ...   \n74995                 29.135447                   1                      1   \n74996                 39.323569                   1                      1   \n74997                 34.663572                   1                      1   \n74998                 40.565631                   1                      1   \n74999                 41.255522                   1                      1   \n\n       Total_EMI_per_month  Amount_invested_monthly  Payment_Behaviour  \\\n0                49.574949                21.465380                  2   \n1                49.574949                21.465380                  3   \n2                49.574949                21.465380                  4   \n3                49.574949                21.465380                  5   \n4                49.574949                21.465380                  1   \n...                    ...                      ...                ...   \n74995            35.104023                24.028477                  4   \n74996            35.104023                24.028477                  1   \n74997            35.104023                24.028477                  0   \n74998            35.104023                24.028477                  1   \n74999            35.104023                24.028477                  0   \n\n       Monthly_Balance  Credit_Score  \n0           312.494089             2  \n1           284.629162             2  \n2           331.209863             2  \n3           223.451310             2  \n4           341.489231             2  \n...                ...           ...  \n74995       400.104466             1  \n74996       410.256158             0  \n74997       479.866228             0  \n74998       496.651610             0  \n74999       516.809083             0  \n\n[75000 rows x 23 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Customer_ID</th>\n      <th>Month</th>\n      <th>Age</th>\n      <th>Occupation</th>\n      <th>Monthly_Inhand_Salary</th>\n      <th>Num_Bank_Accounts</th>\n      <th>Num_Credit_Card</th>\n      <th>Interest_Rate</th>\n      <th>Num_of_Loan</th>\n      <th>Delay_from_due_date</th>\n      <th>...</th>\n      <th>Credit_Mix</th>\n      <th>Outstanding_Debt</th>\n      <th>Credit_Utilization_Ratio</th>\n      <th>Credit_History_Age</th>\n      <th>Payment_of_Min_Amount</th>\n      <th>Total_EMI_per_month</th>\n      <th>Amount_invested_monthly</th>\n      <th>Payment_Behaviour</th>\n      <th>Monthly_Balance</th>\n      <th>Credit_Score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>576</td>\n      <td>0</td>\n      <td>3</td>\n      <td>12</td>\n      <td>7.509249</td>\n      <td>3.0</td>\n      <td>4.0</td>\n      <td>3.0</td>\n      <td>0</td>\n      <td>3.0</td>\n      <td>...</td>\n      <td>2</td>\n      <td>28.460148</td>\n      <td>26.822620</td>\n      <td>1</td>\n      <td>1</td>\n      <td>49.574949</td>\n      <td>21.465380</td>\n      <td>2</td>\n      <td>312.494089</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>576</td>\n      <td>1</td>\n      <td>3</td>\n      <td>12</td>\n      <td>7.509249</td>\n      <td>3.0</td>\n      <td>4.0</td>\n      <td>3.0</td>\n      <td>0</td>\n      <td>3.0</td>\n      <td>...</td>\n      <td>2</td>\n      <td>28.460148</td>\n      <td>31.944960</td>\n      <td>1</td>\n      <td>1</td>\n      <td>49.574949</td>\n      <td>21.465380</td>\n      <td>3</td>\n      <td>284.629162</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>576</td>\n      <td>2</td>\n      <td>3</td>\n      <td>12</td>\n      <td>7.509249</td>\n      <td>3.0</td>\n      <td>4.0</td>\n      <td>3.0</td>\n      <td>0</td>\n      <td>3.0</td>\n      <td>...</td>\n      <td>2</td>\n      <td>28.460148</td>\n      <td>28.609352</td>\n      <td>1</td>\n      <td>1</td>\n      <td>49.574949</td>\n      <td>21.465380</td>\n      <td>4</td>\n      <td>331.209863</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>576</td>\n      <td>3</td>\n      <td>3</td>\n      <td>12</td>\n      <td>7.509249</td>\n      <td>3.0</td>\n      <td>4.0</td>\n      <td>3.0</td>\n      <td>0</td>\n      <td>5.0</td>\n      <td>...</td>\n      <td>2</td>\n      <td>28.460148</td>\n      <td>31.377862</td>\n      <td>1</td>\n      <td>1</td>\n      <td>49.574949</td>\n      <td>21.465380</td>\n      <td>5</td>\n      <td>223.451310</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>576</td>\n      <td>4</td>\n      <td>3</td>\n      <td>12</td>\n      <td>7.509249</td>\n      <td>3.0</td>\n      <td>4.0</td>\n      <td>3.0</td>\n      <td>0</td>\n      <td>6.0</td>\n      <td>...</td>\n      <td>2</td>\n      <td>28.460148</td>\n      <td>24.797347</td>\n      <td>1</td>\n      <td>1</td>\n      <td>49.574949</td>\n      <td>21.465380</td>\n      <td>1</td>\n      <td>341.489231</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>74995</th>\n      <td>9254</td>\n      <td>1</td>\n      <td>3</td>\n      <td>9</td>\n      <td>8.119522</td>\n      <td>4.0</td>\n      <td>6.0</td>\n      <td>7.0</td>\n      <td>0</td>\n      <td>23.0</td>\n      <td>...</td>\n      <td>2</td>\n      <td>22.413835</td>\n      <td>29.135447</td>\n      <td>1</td>\n      <td>1</td>\n      <td>35.104023</td>\n      <td>24.028477</td>\n      <td>4</td>\n      <td>400.104466</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>74996</th>\n      <td>9254</td>\n      <td>2</td>\n      <td>3</td>\n      <td>9</td>\n      <td>8.119522</td>\n      <td>4.0</td>\n      <td>6.0</td>\n      <td>7.0</td>\n      <td>0</td>\n      <td>20.0</td>\n      <td>...</td>\n      <td>2</td>\n      <td>22.413835</td>\n      <td>39.323569</td>\n      <td>1</td>\n      <td>1</td>\n      <td>35.104023</td>\n      <td>24.028477</td>\n      <td>1</td>\n      <td>410.256158</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>74997</th>\n      <td>9254</td>\n      <td>3</td>\n      <td>3</td>\n      <td>9</td>\n      <td>8.119522</td>\n      <td>4.0</td>\n      <td>6.0</td>\n      <td>7.0</td>\n      <td>0</td>\n      <td>23.0</td>\n      <td>...</td>\n      <td>2</td>\n      <td>22.413835</td>\n      <td>34.663572</td>\n      <td>1</td>\n      <td>1</td>\n      <td>35.104023</td>\n      <td>24.028477</td>\n      <td>0</td>\n      <td>479.866228</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>74998</th>\n      <td>9254</td>\n      <td>4</td>\n      <td>3</td>\n      <td>9</td>\n      <td>8.119522</td>\n      <td>4.0</td>\n      <td>6.0</td>\n      <td>7.0</td>\n      <td>0</td>\n      <td>18.0</td>\n      <td>...</td>\n      <td>2</td>\n      <td>22.413835</td>\n      <td>40.565631</td>\n      <td>1</td>\n      <td>1</td>\n      <td>35.104023</td>\n      <td>24.028477</td>\n      <td>1</td>\n      <td>496.651610</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>74999</th>\n      <td>9254</td>\n      <td>5</td>\n      <td>3</td>\n      <td>9</td>\n      <td>8.119522</td>\n      <td>4.0</td>\n      <td>6.0</td>\n      <td>7.0</td>\n      <td>0</td>\n      <td>27.0</td>\n      <td>...</td>\n      <td>2</td>\n      <td>22.413835</td>\n      <td>41.255522</td>\n      <td>1</td>\n      <td>1</td>\n      <td>35.104023</td>\n      <td>24.028477</td>\n      <td>0</td>\n      <td>516.809083</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>75000 rows × 23 columns</p>\n</div>"
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "outputs": [],
   "source": [
    "scaling_cols = ['Monthly_Inhand_Salary', 'Outstanding_Debt', 'Credit_Utilization_Ratio', 'Total_EMI_per_month',\n",
    "                'Amount_invested_monthly', 'Monthly_Balance']\n",
    "rs = RobustScaler()\n",
    "\n",
    "rs_train_df = train[scaling_cols].copy()\n",
    "rs_test_df = test[scaling_cols].copy()\n",
    "\n",
    "rs_train_df = rs.fit_transform(rs_train_df)\n",
    "rs_test_df = rs.transform(rs_test_df)\n",
    "\n",
    "train[scaling_cols] = rs_train_df\n",
    "test[scaling_cols] = rs_test_df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "outputs": [
    {
     "data": {
      "text/plain": "       Customer_ID  Month  Age  Occupation  Monthly_Inhand_Salary  \\\n0              576      0    3          12              -0.407299   \n1              576      1    3          12              -0.407299   \n2              576      2    3          12              -0.407299   \n3              576      3    3          12              -0.407299   \n4              576      4    3          12              -0.407299   \n...            ...    ...  ...         ...                    ...   \n74995         9254      1    3           9               0.062676   \n74996         9254      2    3           9               0.062676   \n74997         9254      3    3           9               0.062676   \n74998         9254      4    3           9               0.062676   \n74999         9254      5    3           9               0.062676   \n\n       Num_Bank_Accounts  Num_Credit_Card  Interest_Rate  Num_of_Loan  \\\n0                    3.0              4.0            3.0            0   \n1                    3.0              4.0            3.0            0   \n2                    3.0              4.0            3.0            0   \n3                    3.0              4.0            3.0            0   \n4                    3.0              4.0            3.0            0   \n...                  ...              ...            ...          ...   \n74995                4.0              6.0            7.0            0   \n74996                4.0              6.0            7.0            0   \n74997                4.0              6.0            7.0            0   \n74998                4.0              6.0            7.0            0   \n74999                4.0              6.0            7.0            0   \n\n       Delay_from_due_date  ...  Credit_Mix  Outstanding_Debt  \\\n0                      3.0  ...           2         -0.279953   \n1                      3.0  ...           2         -0.279953   \n2                      3.0  ...           2         -0.279953   \n3                      5.0  ...           2         -0.279953   \n4                      6.0  ...           2         -0.279953   \n...                    ...  ...         ...               ...   \n74995                 23.0  ...           2         -0.577496   \n74996                 20.0  ...           2         -0.577496   \n74997                 23.0  ...           2         -0.577496   \n74998                 18.0  ...           2         -0.577496   \n74999                 27.0  ...           2         -0.577496   \n\n       Credit_Utilization_Ratio  Credit_History_Age  Payment_of_Min_Amount  \\\n0                     -0.648697                   1                      1   \n1                     -0.041010                   1                      1   \n2                     -0.436728                   1                      1   \n3                     -0.108287                   1                      1   \n4                     -0.888964                   1                      1   \n...                         ...                 ...                    ...   \n74995                 -0.374315                   1                      1   \n74996                  0.834349                   1                      1   \n74997                  0.281512                   1                      1   \n74998                  0.981701                   1                      1   \n74999                  1.063546                   1                      1   \n\n       Total_EMI_per_month  Amount_invested_monthly  Payment_Behaviour  \\\n0                -0.139504                -0.546677                  2   \n1                -0.139504                -0.546677                  3   \n2                -0.139504                -0.546677                  4   \n3                -0.139504                -0.546677                  5   \n4                -0.139504                -0.546677                  1   \n...                    ...                      ...                ...   \n74995            -0.264438                -0.487533                  4   \n74996            -0.264438                -0.487533                  1   \n74997            -0.264438                -0.487533                  0   \n74998            -0.264438                -0.487533                  1   \n74999            -0.264438                -0.487533                  0   \n\n       Monthly_Balance  Credit_Score  \n0            -0.108344             2  \n1            -0.250764             2  \n2            -0.012686             2  \n3            -0.563450             2  \n4             0.039852             2  \n...                ...           ...  \n74995         0.339440             1  \n74996         0.391326             0  \n74997         0.747110             0  \n74998         0.832901             0  \n74999         0.935928             0  \n\n[75000 rows x 23 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Customer_ID</th>\n      <th>Month</th>\n      <th>Age</th>\n      <th>Occupation</th>\n      <th>Monthly_Inhand_Salary</th>\n      <th>Num_Bank_Accounts</th>\n      <th>Num_Credit_Card</th>\n      <th>Interest_Rate</th>\n      <th>Num_of_Loan</th>\n      <th>Delay_from_due_date</th>\n      <th>...</th>\n      <th>Credit_Mix</th>\n      <th>Outstanding_Debt</th>\n      <th>Credit_Utilization_Ratio</th>\n      <th>Credit_History_Age</th>\n      <th>Payment_of_Min_Amount</th>\n      <th>Total_EMI_per_month</th>\n      <th>Amount_invested_monthly</th>\n      <th>Payment_Behaviour</th>\n      <th>Monthly_Balance</th>\n      <th>Credit_Score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>576</td>\n      <td>0</td>\n      <td>3</td>\n      <td>12</td>\n      <td>-0.407299</td>\n      <td>3.0</td>\n      <td>4.0</td>\n      <td>3.0</td>\n      <td>0</td>\n      <td>3.0</td>\n      <td>...</td>\n      <td>2</td>\n      <td>-0.279953</td>\n      <td>-0.648697</td>\n      <td>1</td>\n      <td>1</td>\n      <td>-0.139504</td>\n      <td>-0.546677</td>\n      <td>2</td>\n      <td>-0.108344</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>576</td>\n      <td>1</td>\n      <td>3</td>\n      <td>12</td>\n      <td>-0.407299</td>\n      <td>3.0</td>\n      <td>4.0</td>\n      <td>3.0</td>\n      <td>0</td>\n      <td>3.0</td>\n      <td>...</td>\n      <td>2</td>\n      <td>-0.279953</td>\n      <td>-0.041010</td>\n      <td>1</td>\n      <td>1</td>\n      <td>-0.139504</td>\n      <td>-0.546677</td>\n      <td>3</td>\n      <td>-0.250764</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>576</td>\n      <td>2</td>\n      <td>3</td>\n      <td>12</td>\n      <td>-0.407299</td>\n      <td>3.0</td>\n      <td>4.0</td>\n      <td>3.0</td>\n      <td>0</td>\n      <td>3.0</td>\n      <td>...</td>\n      <td>2</td>\n      <td>-0.279953</td>\n      <td>-0.436728</td>\n      <td>1</td>\n      <td>1</td>\n      <td>-0.139504</td>\n      <td>-0.546677</td>\n      <td>4</td>\n      <td>-0.012686</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>576</td>\n      <td>3</td>\n      <td>3</td>\n      <td>12</td>\n      <td>-0.407299</td>\n      <td>3.0</td>\n      <td>4.0</td>\n      <td>3.0</td>\n      <td>0</td>\n      <td>5.0</td>\n      <td>...</td>\n      <td>2</td>\n      <td>-0.279953</td>\n      <td>-0.108287</td>\n      <td>1</td>\n      <td>1</td>\n      <td>-0.139504</td>\n      <td>-0.546677</td>\n      <td>5</td>\n      <td>-0.563450</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>576</td>\n      <td>4</td>\n      <td>3</td>\n      <td>12</td>\n      <td>-0.407299</td>\n      <td>3.0</td>\n      <td>4.0</td>\n      <td>3.0</td>\n      <td>0</td>\n      <td>6.0</td>\n      <td>...</td>\n      <td>2</td>\n      <td>-0.279953</td>\n      <td>-0.888964</td>\n      <td>1</td>\n      <td>1</td>\n      <td>-0.139504</td>\n      <td>-0.546677</td>\n      <td>1</td>\n      <td>0.039852</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>74995</th>\n      <td>9254</td>\n      <td>1</td>\n      <td>3</td>\n      <td>9</td>\n      <td>0.062676</td>\n      <td>4.0</td>\n      <td>6.0</td>\n      <td>7.0</td>\n      <td>0</td>\n      <td>23.0</td>\n      <td>...</td>\n      <td>2</td>\n      <td>-0.577496</td>\n      <td>-0.374315</td>\n      <td>1</td>\n      <td>1</td>\n      <td>-0.264438</td>\n      <td>-0.487533</td>\n      <td>4</td>\n      <td>0.339440</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>74996</th>\n      <td>9254</td>\n      <td>2</td>\n      <td>3</td>\n      <td>9</td>\n      <td>0.062676</td>\n      <td>4.0</td>\n      <td>6.0</td>\n      <td>7.0</td>\n      <td>0</td>\n      <td>20.0</td>\n      <td>...</td>\n      <td>2</td>\n      <td>-0.577496</td>\n      <td>0.834349</td>\n      <td>1</td>\n      <td>1</td>\n      <td>-0.264438</td>\n      <td>-0.487533</td>\n      <td>1</td>\n      <td>0.391326</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>74997</th>\n      <td>9254</td>\n      <td>3</td>\n      <td>3</td>\n      <td>9</td>\n      <td>0.062676</td>\n      <td>4.0</td>\n      <td>6.0</td>\n      <td>7.0</td>\n      <td>0</td>\n      <td>23.0</td>\n      <td>...</td>\n      <td>2</td>\n      <td>-0.577496</td>\n      <td>0.281512</td>\n      <td>1</td>\n      <td>1</td>\n      <td>-0.264438</td>\n      <td>-0.487533</td>\n      <td>0</td>\n      <td>0.747110</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>74998</th>\n      <td>9254</td>\n      <td>4</td>\n      <td>3</td>\n      <td>9</td>\n      <td>0.062676</td>\n      <td>4.0</td>\n      <td>6.0</td>\n      <td>7.0</td>\n      <td>0</td>\n      <td>18.0</td>\n      <td>...</td>\n      <td>2</td>\n      <td>-0.577496</td>\n      <td>0.981701</td>\n      <td>1</td>\n      <td>1</td>\n      <td>-0.264438</td>\n      <td>-0.487533</td>\n      <td>1</td>\n      <td>0.832901</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>74999</th>\n      <td>9254</td>\n      <td>5</td>\n      <td>3</td>\n      <td>9</td>\n      <td>0.062676</td>\n      <td>4.0</td>\n      <td>6.0</td>\n      <td>7.0</td>\n      <td>0</td>\n      <td>27.0</td>\n      <td>...</td>\n      <td>2</td>\n      <td>-0.577496</td>\n      <td>1.063546</td>\n      <td>1</td>\n      <td>1</td>\n      <td>-0.264438</td>\n      <td>-0.487533</td>\n      <td>0</td>\n      <td>0.935928</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>75000 rows × 23 columns</p>\n</div>"
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "outputs": [],
   "source": [
    "x_train = train.loc[:, all_col_list].values\n",
    "y_train = train.loc[:, target].values\n",
    "x_test = test.loc[:, all_col_list].values\n",
    "y_test = test.loc[:, target].values"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before SMOTE ENN....\n",
      "The shape of your X data:  (75000, 21)\n",
      "The shape of your y data:  (75000,)\n",
      "Label Counts : \n",
      " 0    21782\n",
      "1    40214\n",
      "2    13004\n",
      "dtype: int64\n",
      "\n",
      "\n",
      "After SMOTE ENN Applied....\n",
      "The shape of your X_SME data:  (111776, 21)\n",
      "The shape of your y_SME data:  (111776,)\n",
      "Label Counts : \n",
      " 0    40214\n",
      "1    32145\n",
      "2    39417\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "x_sme, y_sme = sampling_smote_enn(x_train, y_train, smote=smote, enn=enn)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[ 5.15400000e+03,  0.00000000e+00,  4.00000000e+00, ...,\n        -3.65283721e-01,  3.00000000e+00, -1.81442738e-01],\n       [ 5.15400000e+03,  1.00000000e+00,  4.00000000e+00, ...,\n        -3.65283721e-01,  0.00000000e+00,  2.99020207e-01],\n       [ 5.15400000e+03,  2.00000000e+00,  4.00000000e+00, ...,\n        -3.65283721e-01,  3.00000000e+00, -3.71982890e-01],\n       ...,\n       [ 1.20400000e+03,  3.99286109e+00,  3.00000000e+00, ...,\n        -4.48625139e-01,  4.66428703e+00, -4.89804132e-01],\n       [ 6.03200000e+03,  2.79147460e+00,  5.00000000e+00, ...,\n         7.62443094e-01,  2.81278811e+00,  1.22128162e-01],\n       [ 7.83537651e+03,  3.62349488e+00,  3.37650512e+00, ...,\n         5.66464894e-02,  2.37650512e+00,  6.34319339e-01]])"
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_sme"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device used : cpu\n",
      "No early stopping will be performed, last training weights will be used.\n",
      "epoch 0  | loss: 1.92609 |  0:00:23s\n",
      "epoch 1  | loss: 1.29888 |  0:00:46s\n",
      "epoch 2  | loss: 1.05071 |  0:01:08s\n",
      "epoch 3  | loss: 0.9612  |  0:01:29s\n",
      "epoch 4  | loss: 0.91404 |  0:01:52s\n",
      "epoch 5  | loss: 0.89945 |  0:02:16s\n",
      "epoch 6  | loss: 0.88479 |  0:02:39s\n",
      "epoch 7  | loss: 0.87487 |  0:03:03s\n",
      "epoch 8  | loss: 0.86847 |  0:03:26s\n",
      "epoch 9  | loss: 0.86599 |  0:03:59s\n",
      "epoch 10 | loss: 0.86448 |  0:04:38s\n",
      "epoch 11 | loss: 0.86372 |  0:05:18s\n",
      "epoch 12 | loss: 0.86217 |  0:05:52s\n",
      "epoch 13 | loss: 0.85986 |  0:06:23s\n",
      "epoch 14 | loss: 0.85848 |  0:06:49s\n",
      "epoch 15 | loss: 0.85799 |  0:07:12s\n",
      "epoch 16 | loss: 0.856   |  0:07:50s\n",
      "epoch 17 | loss: 0.85533 |  0:08:32s\n",
      "epoch 18 | loss: 0.85386 |  0:09:15s\n",
      "epoch 19 | loss: 0.85361 |  0:09:41s\n",
      "epoch 20 | loss: 0.8538  |  0:10:00s\n",
      "epoch 21 | loss: 0.85294 |  0:10:20s\n",
      "epoch 22 | loss: 0.85188 |  0:10:41s\n",
      "epoch 23 | loss: 0.85283 |  0:11:01s\n",
      "epoch 24 | loss: 0.84975 |  0:11:22s\n",
      "epoch 25 | loss: 0.84815 |  0:11:41s\n",
      "epoch 26 | loss: 0.84391 |  0:12:02s\n",
      "epoch 27 | loss: 0.84099 |  0:12:23s\n",
      "epoch 28 | loss: 0.83739 |  0:12:42s\n",
      "epoch 29 | loss: 0.83377 |  0:13:02s\n",
      "epoch 30 | loss: 0.83172 |  0:13:23s\n",
      "epoch 31 | loss: 0.82886 |  0:13:44s\n",
      "epoch 32 | loss: 0.82628 |  0:14:03s\n",
      "epoch 33 | loss: 0.82308 |  0:14:26s\n",
      "epoch 34 | loss: 0.81886 |  0:14:47s\n",
      "epoch 35 | loss: 0.81535 |  0:15:07s\n",
      "epoch 36 | loss: 0.81203 |  0:15:25s\n",
      "epoch 37 | loss: 0.8086  |  0:15:47s\n",
      "epoch 38 | loss: 0.80412 |  0:16:06s\n",
      "epoch 39 | loss: 0.79998 |  0:16:26s\n",
      "epoch 40 | loss: 0.79636 |  0:16:46s\n",
      "epoch 41 | loss: 0.79341 |  0:17:07s\n",
      "epoch 42 | loss: 0.79075 |  0:17:28s\n",
      "epoch 43 | loss: 0.78632 |  0:17:48s\n",
      "epoch 44 | loss: 0.78386 |  0:18:05s\n",
      "epoch 45 | loss: 0.78131 |  0:18:23s\n",
      "epoch 46 | loss: 0.77704 |  0:18:44s\n",
      "epoch 47 | loss: 0.76261 |  0:19:03s\n",
      "epoch 48 | loss: 0.7398  |  0:19:24s\n",
      "epoch 49 | loss: 0.71363 |  0:19:46s\n",
      "epoch 50 | loss: 0.68385 |  0:20:06s\n",
      "epoch 51 | loss: 0.6514  |  0:20:26s\n",
      "epoch 52 | loss: 0.61883 |  0:20:46s\n",
      "epoch 53 | loss: 0.58538 |  0:21:06s\n",
      "epoch 54 | loss: 0.5545  |  0:21:33s\n",
      "epoch 55 | loss: 0.52464 |  0:21:53s\n",
      "epoch 56 | loss: 0.49782 |  0:22:14s\n",
      "epoch 57 | loss: 0.47418 |  0:22:34s\n",
      "epoch 58 | loss: 0.45147 |  0:22:54s\n",
      "epoch 59 | loss: 0.43117 |  0:23:14s\n",
      "epoch 60 | loss: 0.41307 |  0:23:39s\n",
      "epoch 61 | loss: 0.39842 |  0:24:01s\n",
      "epoch 62 | loss: 0.38309 |  0:24:20s\n",
      "epoch 63 | loss: 0.36933 |  0:24:40s\n",
      "epoch 64 | loss: 0.35614 |  0:25:00s\n",
      "epoch 65 | loss: 0.34548 |  0:25:22s\n",
      "epoch 66 | loss: 0.33555 |  0:25:43s\n",
      "epoch 67 | loss: 0.3269  |  0:26:02s\n",
      "epoch 68 | loss: 0.31982 |  0:26:24s\n",
      "epoch 69 | loss: 0.31347 |  0:26:44s\n",
      "epoch 70 | loss: 0.30755 |  0:27:04s\n",
      "epoch 71 | loss: 0.30225 |  0:27:27s\n",
      "epoch 72 | loss: 0.29719 |  0:27:47s\n",
      "epoch 73 | loss: 0.29338 |  0:28:07s\n",
      "epoch 74 | loss: 0.28904 |  0:28:31s\n",
      "epoch 75 | loss: 0.28597 |  0:28:57s\n",
      "epoch 76 | loss: 0.28236 |  0:29:18s\n",
      "epoch 77 | loss: 0.27986 |  0:29:38s\n",
      "epoch 78 | loss: 0.27677 |  0:30:00s\n",
      "epoch 79 | loss: 0.2756  |  0:30:30s\n",
      "epoch 80 | loss: 0.27326 |  0:30:56s\n",
      "epoch 81 | loss: 0.2718  |  0:31:21s\n",
      "epoch 82 | loss: 0.26947 |  0:31:44s\n",
      "epoch 83 | loss: 0.26804 |  0:32:05s\n",
      "epoch 84 | loss: 0.26673 |  0:32:27s\n",
      "epoch 85 | loss: 0.2653  |  0:32:51s\n",
      "epoch 86 | loss: 0.26389 |  0:33:16s\n",
      "epoch 87 | loss: 0.26349 |  0:33:35s\n",
      "epoch 88 | loss: 0.2618  |  0:33:53s\n",
      "epoch 89 | loss: 0.26098 |  0:34:17s\n"
     ]
    }
   ],
   "source": [
    "# pretrain model\n",
    "unsupervised_model = TabNetPretrainer(\n",
    "    cat_idxs=cat_col_idx,\n",
    "    cat_dims=cat_col_dims,\n",
    "    cat_emb_dim=[int(round(np.sqrt(i)/4,0))+1 for i in cat_col_dims],\n",
    "    optimizer_fn=torch.optim.Adam,\n",
    "    optimizer_params=dict(lr=5*1e-3),\n",
    "    scheduler_params={'is_batch_level': True, 'T_0':10, 'T_mult':2, 'eta_min': 0.001},\n",
    "    scheduler_fn=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts,\n",
    "    mask_type='entmax'\n",
    ")\n",
    "\n",
    "unsupervised_model.fit(\n",
    "    X_train=x_sme,\n",
    "    max_epochs=90,\n",
    "    drop_last=False,\n",
    "    pretraining_ratio=0.6, #0.5\n",
    ")\n",
    "\n",
    "reconstructed_X, embedded_X = unsupervised_model.predict(x_sme)\n",
    "assert(reconstructed_X.shape == embedded_X.shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device used : cpu\n"
     ]
    }
   ],
   "source": [
    "model = TabNetClassifier(\n",
    "    cat_idxs=cat_col_idx,\n",
    "    cat_dims=cat_col_dims,\n",
    "    cat_emb_dim=[int(round(np.sqrt(i)/4,0))+1 for i in cat_col_dims],\n",
    "    optimizer_fn=torch.optim.Adam,\n",
    "    optimizer_params=dict(lr=1e-3),\n",
    "    scheduler_params={'is_batch_level': True, 'T_0':10, 'T_mult':2, 'eta_min': 0.001},\n",
    "    scheduler_fn=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts,\n",
    "    mask_type='sparsemax',\n",
    "    gamma=1.3,\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading weights from unsupervised pretraining\n",
      "epoch 0  | loss: 1.23795 | train_balanced_accuracy: 0.77028 | train_accuracy: 0.77688 |  0:00:27s\n",
      "epoch 1  | loss: 0.5744  | train_balanced_accuracy: 0.79475 | train_accuracy: 0.79874 |  0:00:52s\n",
      "epoch 2  | loss: 0.50857 | train_balanced_accuracy: 0.84184 | train_accuracy: 0.84331 |  0:01:12s\n",
      "epoch 3  | loss: 0.41715 | train_balanced_accuracy: 0.88141 | train_accuracy: 0.88328 |  0:01:31s\n",
      "epoch 4  | loss: 0.32764 | train_balanced_accuracy: 0.91061 | train_accuracy: 0.91178 |  0:01:52s\n",
      "epoch 5  | loss: 0.26425 | train_balanced_accuracy: 0.92638 | train_accuracy: 0.92691 |  0:02:11s\n",
      "epoch 6  | loss: 0.22606 | train_balanced_accuracy: 0.93366 | train_accuracy: 0.9341  |  0:02:33s\n",
      "epoch 7  | loss: 0.19932 | train_balanced_accuracy: 0.94148 | train_accuracy: 0.94203 |  0:02:52s\n",
      "epoch 8  | loss: 0.18134 | train_balanced_accuracy: 0.9476  | train_accuracy: 0.94805 |  0:03:12s\n",
      "epoch 9  | loss: 0.16534 | train_balanced_accuracy: 0.95118 | train_accuracy: 0.95112 |  0:03:31s\n",
      "epoch 10 | loss: 0.15223 | train_balanced_accuracy: 0.95671 | train_accuracy: 0.95741 |  0:03:52s\n",
      "epoch 11 | loss: 0.14286 | train_balanced_accuracy: 0.95996 | train_accuracy: 0.96092 |  0:04:13s\n",
      "epoch 12 | loss: 0.13073 | train_balanced_accuracy: 0.96238 | train_accuracy: 0.96299 |  0:04:36s\n",
      "epoch 13 | loss: 0.12183 | train_balanced_accuracy: 0.9638  | train_accuracy: 0.9646  |  0:05:05s\n",
      "epoch 14 | loss: 0.11508 | train_balanced_accuracy: 0.96832 | train_accuracy: 0.9694  |  0:05:36s\n",
      "epoch 15 | loss: 0.10889 | train_balanced_accuracy: 0.97024 | train_accuracy: 0.97103 |  0:06:03s\n",
      "epoch 16 | loss: 0.10201 | train_balanced_accuracy: 0.97005 | train_accuracy: 0.97153 |  0:06:39s\n",
      "epoch 17 | loss: 0.0983  | train_balanced_accuracy: 0.97326 | train_accuracy: 0.97359 |  0:07:06s\n",
      "epoch 18 | loss: 0.09368 | train_balanced_accuracy: 0.97491 | train_accuracy: 0.97559 |  0:07:29s\n",
      "epoch 19 | loss: 0.08904 | train_balanced_accuracy: 0.97609 | train_accuracy: 0.97682 |  0:08:10s\n",
      "epoch 20 | loss: 0.0854  | train_balanced_accuracy: 0.97503 | train_accuracy: 0.97555 |  0:08:36s\n",
      "epoch 21 | loss: 0.08191 | train_balanced_accuracy: 0.97762 | train_accuracy: 0.97844 |  0:08:59s\n",
      "epoch 22 | loss: 0.07874 | train_balanced_accuracy: 0.97999 | train_accuracy: 0.98048 |  0:09:24s\n",
      "epoch 23 | loss: 0.07728 | train_balanced_accuracy: 0.9774  | train_accuracy: 0.97768 |  0:09:46s\n",
      "epoch 24 | loss: 0.07418 | train_balanced_accuracy: 0.98075 | train_accuracy: 0.9814  |  0:10:08s\n",
      "epoch 25 | loss: 0.07004 | train_balanced_accuracy: 0.98046 | train_accuracy: 0.98087 |  0:10:32s\n",
      "epoch 26 | loss: 0.06798 | train_balanced_accuracy: 0.98228 | train_accuracy: 0.98286 |  0:10:56s\n",
      "epoch 27 | loss: 0.06674 | train_balanced_accuracy: 0.98253 | train_accuracy: 0.98331 |  0:11:18s\n",
      "epoch 28 | loss: 0.06423 | train_balanced_accuracy: 0.98396 | train_accuracy: 0.98429 |  0:11:36s\n",
      "epoch 29 | loss: 0.06207 | train_balanced_accuracy: 0.98311 | train_accuracy: 0.9838  |  0:11:57s\n",
      "epoch 30 | loss: 0.06032 | train_balanced_accuracy: 0.98394 | train_accuracy: 0.98415 |  0:12:18s\n",
      "epoch 31 | loss: 0.05815 | train_balanced_accuracy: 0.98621 | train_accuracy: 0.98657 |  0:12:39s\n",
      "epoch 32 | loss: 0.05457 | train_balanced_accuracy: 0.98762 | train_accuracy: 0.98802 |  0:13:04s\n",
      "epoch 33 | loss: 0.05173 | train_balanced_accuracy: 0.98805 | train_accuracy: 0.98846 |  0:13:25s\n",
      "epoch 34 | loss: 0.05108 | train_balanced_accuracy: 0.98816 | train_accuracy: 0.98826 |  0:13:48s\n",
      "epoch 35 | loss: 0.04773 | train_balanced_accuracy: 0.98928 | train_accuracy: 0.98961 |  0:14:14s\n",
      "epoch 36 | loss: 0.04667 | train_balanced_accuracy: 0.98966 | train_accuracy: 0.99    |  0:14:33s\n",
      "epoch 37 | loss: 0.04517 | train_balanced_accuracy: 0.99005 | train_accuracy: 0.99041 |  0:14:55s\n",
      "epoch 38 | loss: 0.04194 | train_balanced_accuracy: 0.99167 | train_accuracy: 0.99191 |  0:15:16s\n",
      "epoch 39 | loss: 0.04086 | train_balanced_accuracy: 0.99157 | train_accuracy: 0.99164 |  0:15:38s\n",
      "epoch 40 | loss: 0.03945 | train_balanced_accuracy: 0.99175 | train_accuracy: 0.99178 |  0:16:02s\n",
      "epoch 41 | loss: 0.03979 | train_balanced_accuracy: 0.99254 | train_accuracy: 0.99272 |  0:16:22s\n",
      "epoch 42 | loss: 0.03819 | train_balanced_accuracy: 0.99258 | train_accuracy: 0.99267 |  0:16:44s\n",
      "epoch 43 | loss: 0.03667 | train_balanced_accuracy: 0.99318 | train_accuracy: 0.99342 |  0:17:07s\n",
      "epoch 44 | loss: 0.03401 | train_balanced_accuracy: 0.99306 | train_accuracy: 0.99325 |  0:17:30s\n",
      "epoch 45 | loss: 0.03465 | train_balanced_accuracy: 0.99293 | train_accuracy: 0.99292 |  0:17:51s\n",
      "epoch 46 | loss: 0.03348 | train_balanced_accuracy: 0.9932  | train_accuracy: 0.99312 |  0:18:10s\n",
      "epoch 47 | loss: 0.03269 | train_balanced_accuracy: 0.99402 | train_accuracy: 0.99407 |  0:18:30s\n",
      "epoch 48 | loss: 0.03213 | train_balanced_accuracy: 0.99401 | train_accuracy: 0.99418 |  0:18:49s\n",
      "epoch 49 | loss: 0.03093 | train_balanced_accuracy: 0.99389 | train_accuracy: 0.9941  |  0:19:08s\n",
      "Stop training because you reached max_epochs = 50 with best_epoch = 48 and best_train_accuracy = 0.99418\n",
      "Best weights from best epoch are automatically used!\n"
     ]
    }
   ],
   "source": [
    "model.fit(\n",
    "    X_train=x_sme,\n",
    "    y_train=y_sme,\n",
    "    eval_set=[(x_sme, y_sme)],\n",
    "    eval_name=['train'],\n",
    "    eval_metric=['balanced_accuracy', 'accuracy'],\n",
    "    max_epochs=50,\n",
    "    patience=5,\n",
    "    weights=0,  # 0: no, 1: balanced, dict: customized\n",
    "    batch_size=512,\n",
    "    virtual_batch_size=128,\n",
    "    num_workers=0,\n",
    "    drop_last=False,\n",
    "    from_unsupervised=unsupervised_model,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Result"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Customer_ID :  0.783\n",
      "Month :  0.02\n",
      "Age :  0.0\n",
      "Monthly_Inhand_Salary :  0.021\n",
      "Num_Bank_Accounts :  0.002\n",
      "Num_Credit_Card :  0.034\n",
      "Interest_Rate :  0.012\n",
      "Num_of_Loan :  0.005\n",
      "Delay_from_due_date :  0.0\n",
      "Num_of_Delayed_Payment :  0.004\n",
      "Changed_Credit_Limit :  0.0\n",
      "Num_Credit_Inquiries :  0.01\n",
      "Credit_Mix :  0.051\n",
      "Outstanding_Debt :  0.018\n",
      "Credit_Utilization_Ratio :  0.0\n",
      "Credit_History_Age :  0.003\n",
      "Payment_of_Min_Amount :  0.021\n",
      "Total_EMI_per_month :  0.003\n",
      "Amount_invested_monthly :  0.002\n",
      "Payment_Behaviour :  0.002\n",
      "Monthly_Balance :  0.009\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(all_col_list)):\n",
    "    print(all_col_list[i], ': ', model.feature_importances_.round(3)[i])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      1.00      0.90     21782\n",
      "           1       0.99      0.82      0.90     40214\n",
      "           2       0.82      0.98      0.89     13004\n",
      "\n",
      "    accuracy                           0.90     75000\n",
      "   macro avg       0.88      0.93      0.90     75000\n",
      "weighted avg       0.91      0.90      0.90     75000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_true=y_train, y_pred=model.predict(x_train)))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "outputs": [],
   "source": [
    "# f1_score(y_train, (model.predict(x_train)))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "outputs": [],
   "source": [
    "predicted = model.predict(x_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7459952728392999\n",
      "0.74704\n"
     ]
    }
   ],
   "source": [
    "print(f1_score(y_test, predicted, average='weighted'))\n",
    "print(accuracy_score(y_test, predicted))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.86      0.78      7216\n",
      "           1       0.81      0.68      0.74     12960\n",
      "           2       0.69      0.77      0.73      4824\n",
      "\n",
      "    accuracy                           0.75     25000\n",
      "   macro avg       0.73      0.77      0.75     25000\n",
      "weighted avg       0.76      0.75      0.75     25000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, predicted))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "기존 대비 0번 클래스를 더 잘맞추나, 2번 클래스에 대한 전반적인 성능은 줄었음"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6181 1007   28]\n",
      " [2513 8768 1679]\n",
      " [  31 1066 3727]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, predicted))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## SMOTE + Tomek"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "outputs": [],
   "source": [
    "def sampling_smote_tomek(x_input, y_input, smote=None, tomek=None, sampling_strategy='auto'):\n",
    "    \"\"\"\n",
    "    :param x_input: x data 입력\n",
    "    :param y_input: y data 입력\n",
    "    :param smote: SMOTE 객체 입력\n",
    "    :param tomek: Tomek 객체 입력\n",
    "    :param sampling_strategy: 딕셔너리 구조로 입력\n",
    "    :return: x_smt, y_smt\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "    from imblearn.combine import SMOTETomek\n",
    "    smt = SMOTETomek(smote=smote,\n",
    "                   tomek=tomek,\n",
    "                   sampling_strategy=sampling_strategy,\n",
    "                   random_state=42,\n",
    "                   n_jobs=-1)\n",
    "\n",
    "    x_smt, y_smt = smt.fit_resample(x_input, y_input)\n",
    "\n",
    "    print(\"Before SMOTE Tomek....\")\n",
    "    print(\"The shape of your X data: \", x_input.shape)\n",
    "    print(\"The shape of your y data: \", y_input.shape)\n",
    "    print(\"Label Counts : \\n\", pd.Series(y_input).value_counts().sort_index())\n",
    "    print('\\n')\n",
    "    print(\"After SMOTE Tomek Applied....\")\n",
    "    print(\"The shape of your X_SME data: \", x_smt.shape)\n",
    "    print(\"The shape of your y_SME data: \", y_smt.shape)\n",
    "    print(\"Label Counts : \\n\", pd.Series(y_smt).value_counts().sort_index())\n",
    "\n",
    "    return x_smt, y_smt"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from imblearn.combine import SMOTETomek"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before SMOTE Tomek....\n",
      "The shape of your X data:  (75000, 21)\n",
      "The shape of your y data:  (75000,)\n",
      "Label Counts : \n",
      " 0    21782\n",
      "1    40214\n",
      "2    13004\n",
      "dtype: int64\n",
      "\n",
      "\n",
      "After SMOTE Tomek Applied....\n",
      "The shape of your X_SME data:  (117826, 21)\n",
      "The shape of your y_SME data:  (117826,)\n",
      "Label Counts : \n",
      " 0    39140\n",
      "1    38806\n",
      "2    39880\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "x_smt, y_smt = sampling_smote_tomek(x_train, y_train)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device used : cpu\n",
      "No early stopping will be performed, last training weights will be used.\n",
      "epoch 0  | loss: 1.89148 |  0:00:23s\n",
      "epoch 1  | loss: 1.25966 |  0:00:43s\n",
      "epoch 2  | loss: 1.04032 |  0:01:06s\n",
      "epoch 3  | loss: 0.946   |  0:01:27s\n",
      "epoch 4  | loss: 0.90628 |  0:01:49s\n",
      "epoch 5  | loss: 0.89407 |  0:02:12s\n",
      "epoch 6  | loss: 0.88076 |  0:02:35s\n",
      "epoch 7  | loss: 0.87257 |  0:02:55s\n",
      "epoch 8  | loss: 0.86935 |  0:03:19s\n",
      "epoch 9  | loss: 0.86748 |  0:03:40s\n",
      "epoch 10 | loss: 0.86619 |  0:04:01s\n",
      "epoch 11 | loss: 0.86439 |  0:04:21s\n",
      "epoch 12 | loss: 0.86199 |  0:04:42s\n",
      "epoch 13 | loss: 0.8589  |  0:05:03s\n",
      "epoch 14 | loss: 0.85741 |  0:05:24s\n",
      "epoch 15 | loss: 0.85616 |  0:05:45s\n",
      "epoch 16 | loss: 0.85427 |  0:06:06s\n",
      "epoch 17 | loss: 0.85363 |  0:06:25s\n",
      "epoch 18 | loss: 0.85188 |  0:06:45s\n",
      "epoch 19 | loss: 0.85156 |  0:07:04s\n",
      "epoch 20 | loss: 0.85061 |  0:07:23s\n",
      "epoch 21 | loss: 0.84999 |  0:07:43s\n",
      "epoch 22 | loss: 0.84998 |  0:08:02s\n",
      "epoch 23 | loss: 0.84689 |  0:08:21s\n",
      "epoch 24 | loss: 0.84516 |  0:08:41s\n",
      "epoch 25 | loss: 0.8434  |  0:09:00s\n",
      "epoch 26 | loss: 0.84124 |  0:09:19s\n",
      "epoch 27 | loss: 0.83549 |  0:09:38s\n",
      "epoch 28 | loss: 0.83072 |  0:09:58s\n",
      "epoch 29 | loss: 0.82375 |  0:10:17s\n",
      "epoch 30 | loss: 0.81851 |  0:10:35s\n",
      "epoch 31 | loss: 0.81181 |  0:10:55s\n",
      "epoch 32 | loss: 0.80445 |  0:11:14s\n",
      "epoch 33 | loss: 0.79709 |  0:11:33s\n",
      "epoch 34 | loss: 0.78876 |  0:11:53s\n",
      "epoch 35 | loss: 0.78063 |  0:12:12s\n",
      "epoch 36 | loss: 0.77202 |  0:12:31s\n",
      "epoch 37 | loss: 0.76587 |  0:12:50s\n",
      "epoch 38 | loss: 0.75837 |  0:13:09s\n",
      "epoch 39 | loss: 0.75124 |  0:13:28s\n",
      "epoch 40 | loss: 0.7436  |  0:13:50s\n",
      "epoch 41 | loss: 0.73712 |  0:14:09s\n",
      "epoch 42 | loss: 0.72919 |  0:14:30s\n",
      "epoch 43 | loss: 0.72303 |  0:14:51s\n",
      "epoch 44 | loss: 0.70884 |  0:15:13s\n",
      "epoch 45 | loss: 0.67827 |  0:15:36s\n",
      "epoch 46 | loss: 0.64336 |  0:15:56s\n",
      "epoch 47 | loss: 0.6064  |  0:16:16s\n",
      "epoch 48 | loss: 0.57277 |  0:16:36s\n",
      "epoch 49 | loss: 0.53752 |  0:16:57s\n",
      "epoch 50 | loss: 0.50716 |  0:17:17s\n",
      "epoch 51 | loss: 0.47759 |  0:17:37s\n",
      "epoch 52 | loss: 0.45019 |  0:17:57s\n",
      "epoch 53 | loss: 0.42745 |  0:18:18s\n",
      "epoch 54 | loss: 0.40631 |  0:18:38s\n",
      "epoch 55 | loss: 0.38704 |  0:18:58s\n",
      "epoch 56 | loss: 0.37153 |  0:19:18s\n",
      "epoch 57 | loss: 0.35681 |  0:19:38s\n",
      "epoch 58 | loss: 0.34307 |  0:20:00s\n",
      "epoch 59 | loss: 0.33131 |  0:20:20s\n",
      "epoch 60 | loss: 0.3219  |  0:20:41s\n",
      "epoch 61 | loss: 0.31317 |  0:21:02s\n",
      "epoch 62 | loss: 0.30493 |  0:21:22s\n",
      "epoch 63 | loss: 0.29743 |  0:21:41s\n",
      "epoch 64 | loss: 0.29093 |  0:22:01s\n",
      "epoch 65 | loss: 0.28563 |  0:22:20s\n",
      "epoch 66 | loss: 0.28073 |  0:22:39s\n",
      "epoch 67 | loss: 0.27598 |  0:22:58s\n",
      "epoch 68 | loss: 0.27224 |  0:23:18s\n",
      "epoch 69 | loss: 0.26822 |  0:23:37s\n",
      "epoch 70 | loss: 0.26513 |  0:23:56s\n",
      "epoch 71 | loss: 0.26151 |  0:24:16s\n",
      "epoch 72 | loss: 0.25966 |  0:24:35s\n",
      "epoch 73 | loss: 0.25641 |  0:24:56s\n",
      "epoch 74 | loss: 0.25508 |  0:25:15s\n",
      "epoch 75 | loss: 0.25344 |  0:25:35s\n",
      "epoch 76 | loss: 0.25157 |  0:25:54s\n",
      "epoch 77 | loss: 0.24986 |  0:26:14s\n",
      "epoch 78 | loss: 0.24784 |  0:26:33s\n",
      "epoch 79 | loss: 0.24667 |  0:26:53s\n",
      "epoch 80 | loss: 0.24579 |  0:27:12s\n",
      "epoch 81 | loss: 0.24443 |  0:27:32s\n",
      "epoch 82 | loss: 0.24304 |  0:27:51s\n",
      "epoch 83 | loss: 0.24223 |  0:28:10s\n",
      "epoch 84 | loss: 0.2412  |  0:28:30s\n",
      "epoch 85 | loss: 0.24018 |  0:28:49s\n",
      "epoch 86 | loss: 0.23953 |  0:29:08s\n",
      "epoch 87 | loss: 0.23928 |  0:29:27s\n",
      "epoch 88 | loss: 0.23828 |  0:29:47s\n",
      "epoch 89 | loss: 0.23659 |  0:30:06s\n"
     ]
    }
   ],
   "source": [
    "# pretrain model\n",
    "unsupervised_model = TabNetPretrainer(\n",
    "    cat_idxs=cat_col_idx,\n",
    "    cat_dims=cat_col_dims,\n",
    "    cat_emb_dim=[int(round(np.sqrt(i)/4,0))+1 for i in cat_col_dims],\n",
    "    optimizer_fn=torch.optim.Adam,\n",
    "    optimizer_params=dict(lr=5*1e-3),\n",
    "    scheduler_params={'is_batch_level': True, 'T_0':10, 'T_mult':2, 'eta_min': 0.001},\n",
    "    scheduler_fn=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts,\n",
    "    mask_type='entmax'\n",
    ")\n",
    "\n",
    "unsupervised_model.fit(\n",
    "    X_train=x_smt,\n",
    "    max_epochs=90,\n",
    "    drop_last=False,\n",
    "    pretraining_ratio=0.6, #0.5\n",
    ")\n",
    "\n",
    "reconstructed_X, embedded_X = unsupervised_model.predict(x_smt)\n",
    "assert(reconstructed_X.shape == embedded_X.shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device used : cpu\n"
     ]
    }
   ],
   "source": [
    "model = TabNetClassifier(\n",
    "    cat_idxs=cat_col_idx,\n",
    "    cat_dims=cat_col_dims,\n",
    "    cat_emb_dim=[int(round(np.sqrt(i)/4,0))+1 for i in cat_col_dims],\n",
    "    optimizer_fn=torch.optim.Adam,\n",
    "    optimizer_params=dict(lr=1e-3),\n",
    "    scheduler_params={'is_batch_level': True, 'T_0':10, 'T_mult':2, 'eta_min': 0.001},\n",
    "    scheduler_fn=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts,\n",
    "    mask_type='sparsemax',\n",
    "    gamma=1.3,\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading weights from unsupervised pretraining\n",
      "epoch 0  | loss: 1.10336 | train_balanced_accuracy: 0.74801 | train_accuracy: 0.7487  |  0:00:19s\n",
      "epoch 1  | loss: 0.60049 | train_balanced_accuracy: 0.79899 | train_accuracy: 0.79973 |  0:00:38s\n",
      "epoch 2  | loss: 0.48007 | train_balanced_accuracy: 0.85818 | train_accuracy: 0.85847 |  0:00:59s\n",
      "epoch 3  | loss: 0.39898 | train_balanced_accuracy: 0.88141 | train_accuracy: 0.88159 |  0:01:19s\n",
      "epoch 4  | loss: 0.34355 | train_balanced_accuracy: 0.89608 | train_accuracy: 0.89639 |  0:01:38s\n",
      "epoch 5  | loss: 0.31148 | train_balanced_accuracy: 0.90114 | train_accuracy: 0.90152 |  0:01:57s\n",
      "epoch 6  | loss: 0.28361 | train_balanced_accuracy: 0.90789 | train_accuracy: 0.90829 |  0:02:17s\n",
      "epoch 7  | loss: 0.26747 | train_balanced_accuracy: 0.90838 | train_accuracy: 0.90881 |  0:02:36s\n",
      "epoch 8  | loss: 0.256   | train_balanced_accuracy: 0.91657 | train_accuracy: 0.91699 |  0:02:54s\n",
      "epoch 9  | loss: 0.24337 | train_balanced_accuracy: 0.91978 | train_accuracy: 0.92021 |  0:03:14s\n",
      "epoch 10 | loss: 0.23283 | train_balanced_accuracy: 0.91984 | train_accuracy: 0.92032 |  0:03:33s\n",
      "epoch 11 | loss: 0.22276 | train_balanced_accuracy: 0.92561 | train_accuracy: 0.92615 |  0:03:52s\n",
      "epoch 12 | loss: 0.21111 | train_balanced_accuracy: 0.93202 | train_accuracy: 0.93248 |  0:04:11s\n",
      "epoch 13 | loss: 0.20305 | train_balanced_accuracy: 0.93614 | train_accuracy: 0.93662 |  0:04:30s\n",
      "epoch 14 | loss: 0.19278 | train_balanced_accuracy: 0.94167 | train_accuracy: 0.94209 |  0:04:49s\n",
      "epoch 15 | loss: 0.18409 | train_balanced_accuracy: 0.94263 | train_accuracy: 0.94301 |  0:05:08s\n",
      "epoch 16 | loss: 0.17665 | train_balanced_accuracy: 0.94505 | train_accuracy: 0.94548 |  0:05:27s\n",
      "epoch 17 | loss: 0.17091 | train_balanced_accuracy: 0.94742 | train_accuracy: 0.94778 |  0:05:46s\n",
      "epoch 18 | loss: 0.16427 | train_balanced_accuracy: 0.95002 | train_accuracy: 0.95036 |  0:06:05s\n",
      "epoch 19 | loss: 0.1596  | train_balanced_accuracy: 0.94961 | train_accuracy: 0.94994 |  0:06:24s\n",
      "epoch 20 | loss: 0.15436 | train_balanced_accuracy: 0.95109 | train_accuracy: 0.95127 |  0:06:43s\n",
      "epoch 21 | loss: 0.14896 | train_balanced_accuracy: 0.9544  | train_accuracy: 0.9547  |  0:07:02s\n",
      "epoch 22 | loss: 0.14533 | train_balanced_accuracy: 0.95628 | train_accuracy: 0.95659 |  0:07:20s\n",
      "epoch 23 | loss: 0.14091 | train_balanced_accuracy: 0.95611 | train_accuracy: 0.95633 |  0:07:39s\n",
      "epoch 24 | loss: 0.13693 | train_balanced_accuracy: 0.95737 | train_accuracy: 0.95767 |  0:07:58s\n",
      "epoch 25 | loss: 0.13119 | train_balanced_accuracy: 0.95981 | train_accuracy: 0.96009 |  0:08:17s\n",
      "epoch 26 | loss: 0.12883 | train_balanced_accuracy: 0.96108 | train_accuracy: 0.96136 |  0:08:36s\n",
      "epoch 27 | loss: 0.12525 | train_balanced_accuracy: 0.96339 | train_accuracy: 0.96364 |  0:08:54s\n",
      "epoch 28 | loss: 0.1213  | train_balanced_accuracy: 0.96351 | train_accuracy: 0.96379 |  0:09:15s\n",
      "epoch 29 | loss: 0.11863 | train_balanced_accuracy: 0.96376 | train_accuracy: 0.96398 |  0:09:34s\n",
      "epoch 30 | loss: 0.11461 | train_balanced_accuracy: 0.96512 | train_accuracy: 0.96533 |  0:09:53s\n",
      "epoch 31 | loss: 0.11318 | train_balanced_accuracy: 0.9665  | train_accuracy: 0.96671 |  0:10:13s\n",
      "epoch 32 | loss: 0.10921 | train_balanced_accuracy: 0.96592 | train_accuracy: 0.96611 |  0:10:33s\n",
      "epoch 33 | loss: 0.1091  | train_balanced_accuracy: 0.96823 | train_accuracy: 0.96843 |  0:10:51s\n",
      "epoch 34 | loss: 0.1064  | train_balanced_accuracy: 0.96742 | train_accuracy: 0.96763 |  0:11:14s\n",
      "epoch 35 | loss: 0.10263 | train_balanced_accuracy: 0.96925 | train_accuracy: 0.96947 |  0:11:34s\n",
      "epoch 36 | loss: 0.09915 | train_balanced_accuracy: 0.97026 | train_accuracy: 0.97048 |  0:11:54s\n",
      "epoch 37 | loss: 0.09843 | train_balanced_accuracy: 0.97174 | train_accuracy: 0.97189 |  0:12:13s\n",
      "epoch 38 | loss: 0.0955  | train_balanced_accuracy: 0.97252 | train_accuracy: 0.97271 |  0:12:33s\n",
      "epoch 39 | loss: 0.09301 | train_balanced_accuracy: 0.9694  | train_accuracy: 0.9695  |  0:12:51s\n",
      "epoch 40 | loss: 0.09299 | train_balanced_accuracy: 0.97294 | train_accuracy: 0.97315 |  0:13:10s\n",
      "epoch 41 | loss: 0.09017 | train_balanced_accuracy: 0.97407 | train_accuracy: 0.97426 |  0:13:29s\n",
      "epoch 42 | loss: 0.08806 | train_balanced_accuracy: 0.97279 | train_accuracy: 0.97297 |  0:13:48s\n",
      "epoch 43 | loss: 0.08821 | train_balanced_accuracy: 0.97525 | train_accuracy: 0.97546 |  0:14:07s\n",
      "epoch 44 | loss: 0.08473 | train_balanced_accuracy: 0.97406 | train_accuracy: 0.97423 |  0:14:25s\n",
      "epoch 45 | loss: 0.0838  | train_balanced_accuracy: 0.97601 | train_accuracy: 0.97608 |  0:14:45s\n",
      "epoch 46 | loss: 0.08222 | train_balanced_accuracy: 0.97685 | train_accuracy: 0.97702 |  0:15:04s\n",
      "epoch 47 | loss: 0.07985 | train_balanced_accuracy: 0.97677 | train_accuracy: 0.97691 |  0:15:23s\n",
      "epoch 48 | loss: 0.07843 | train_balanced_accuracy: 0.9774  | train_accuracy: 0.97758 |  0:15:42s\n",
      "epoch 49 | loss: 0.07673 | train_balanced_accuracy: 0.97874 | train_accuracy: 0.97883 |  0:16:00s\n",
      "Stop training because you reached max_epochs = 50 with best_epoch = 49 and best_train_accuracy = 0.97883\n",
      "Best weights from best epoch are automatically used!\n"
     ]
    }
   ],
   "source": [
    "model.fit(\n",
    "    X_train=x_smt,\n",
    "    y_train=y_smt,\n",
    "    eval_set=[(x_smt, y_smt)],\n",
    "    eval_name=['train'],\n",
    "    eval_metric=['balanced_accuracy', 'accuracy'],\n",
    "    max_epochs=50,\n",
    "    patience=5,\n",
    "    weights=0,  # 0: no, 1: balanced, dict: customized\n",
    "    batch_size=512,\n",
    "    virtual_batch_size=128,\n",
    "    num_workers=0,\n",
    "    drop_last=False,\n",
    "    from_unsupervised=unsupervised_model,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Result"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Customer_ID :  0.911\n",
      "Month :  0.032\n",
      "Age :  0.003\n",
      "Monthly_Inhand_Salary :  0.006\n",
      "Num_Bank_Accounts :  0.001\n",
      "Num_Credit_Card :  0.002\n",
      "Interest_Rate :  0.006\n",
      "Num_of_Loan :  0.001\n",
      "Delay_from_due_date :  0.0\n",
      "Num_of_Delayed_Payment :  0.0\n",
      "Changed_Credit_Limit :  0.002\n",
      "Num_Credit_Inquiries :  0.003\n",
      "Credit_Mix :  0.012\n",
      "Outstanding_Debt :  0.012\n",
      "Credit_Utilization_Ratio :  0.0\n",
      "Credit_History_Age :  0.002\n",
      "Payment_of_Min_Amount :  0.007\n",
      "Total_EMI_per_month :  0.0\n",
      "Amount_invested_monthly :  0.0\n",
      "Payment_Behaviour :  0.001\n",
      "Monthly_Balance :  0.001\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(all_col_list)):\n",
    "    print(all_col_list[i], ': ', model.feature_importances_.round(3)[i])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.98      0.96     21782\n",
      "           1       0.98      0.93      0.96     40214\n",
      "           2       0.93      0.98      0.95     13004\n",
      "\n",
      "    accuracy                           0.96     75000\n",
      "   macro avg       0.95      0.96      0.95     75000\n",
      "weighted avg       0.96      0.96      0.96     75000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_true=y_train, y_pred=model.predict(x_train)))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "outputs": [],
   "source": [
    "# f1_score(y_train, (model.predict(x_train)))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "outputs": [],
   "source": [
    "predicted = model.predict(x_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7199924944333006\n",
      "0.72028\n"
     ]
    }
   ],
   "source": [
    "print(f1_score(y_test, predicted, average='weighted'))\n",
    "print(accuracy_score(y_test, predicted))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.75      0.73      7216\n",
      "           1       0.73      0.73      0.73     12960\n",
      "           2       0.69      0.66      0.67      4824\n",
      "\n",
      "    accuracy                           0.72     25000\n",
      "   macro avg       0.71      0.71      0.71     25000\n",
      "weighted avg       0.72      0.72      0.72     25000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, predicted))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5391 1806   19]\n",
      " [2132 9449 1379]\n",
      " [  24 1633 3167]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, predicted))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# SMOTE ENN + Cost Sensitive"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "기존 클래스 비율 by SME\n",
    "0    40214\n",
    "1    24534\n",
    "2    37715"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "outputs": [],
   "source": [
    "smote = SMOTE(k_neighbors=7, n_jobs=-1, sampling_strategy={0: 25000, 1: 40214, 2: 25000})"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "outputs": [],
   "source": [
    "enn = EditedNearestNeighbours(kind_sel='mode', n_jobs=-1) # less conservative"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before SMOTE ENN....\n",
      "The shape of your X data:  (75000, 21)\n",
      "The shape of your y data:  (75000,)\n",
      "Label Counts : \n",
      " 0    21782\n",
      "1    40214\n",
      "2    13004\n",
      "dtype: int64\n",
      "\n",
      "\n",
      "After SMOTE ENN Applied....\n",
      "The shape of your X_SME data:  (81548, 21)\n",
      "The shape of your y_SME data:  (81548,)\n",
      "Label Counts : \n",
      " 0    25000\n",
      "1    32769\n",
      "2    23779\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# x_sme, y_sme = sampling_smote_enn(x_train, y_train, smote=smote, enn=enn, sampling_strategy={0: 24534, 1: 40214, 2: 37715})\n",
    "x_sme, y_sme = sampling_smote_enn(x_train, y_train, smote=smote, enn=enn)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device used : cpu\n",
      "No early stopping will be performed, last training weights will be used.\n",
      "epoch 0  | loss: 2.07438 |  0:00:18s\n",
      "epoch 1  | loss: 1.49916 |  0:00:32s\n",
      "epoch 2  | loss: 1.14769 |  0:00:47s\n",
      "epoch 3  | loss: 1.05155 |  0:01:00s\n",
      "epoch 4  | loss: 0.9879  |  0:01:16s\n",
      "epoch 5  | loss: 0.93464 |  0:01:30s\n",
      "epoch 6  | loss: 0.91411 |  0:01:45s\n",
      "epoch 7  | loss: 0.90556 |  0:01:59s\n",
      "epoch 8  | loss: 0.89487 |  0:02:13s\n",
      "epoch 9  | loss: 0.88566 |  0:02:28s\n",
      "epoch 10 | loss: 0.88112 |  0:02:42s\n",
      "epoch 11 | loss: 0.87646 |  0:02:57s\n",
      "epoch 12 | loss: 0.8737  |  0:03:11s\n",
      "epoch 13 | loss: 0.87302 |  0:03:26s\n",
      "epoch 14 | loss: 0.87268 |  0:03:40s\n",
      "epoch 15 | loss: 0.87229 |  0:03:54s\n",
      "epoch 16 | loss: 0.86997 |  0:04:10s\n",
      "epoch 17 | loss: 0.86885 |  0:04:24s\n",
      "epoch 18 | loss: 0.86748 |  0:04:41s\n",
      "epoch 19 | loss: 0.86689 |  0:04:56s\n",
      "epoch 20 | loss: 0.8668  |  0:05:11s\n",
      "epoch 21 | loss: 0.8636  |  0:05:24s\n",
      "epoch 22 | loss: 0.86257 |  0:05:37s\n",
      "epoch 23 | loss: 0.86282 |  0:05:50s\n",
      "epoch 24 | loss: 0.86117 |  0:06:03s\n",
      "epoch 25 | loss: 0.85937 |  0:06:16s\n",
      "epoch 26 | loss: 0.85724 |  0:06:28s\n",
      "epoch 27 | loss: 0.85593 |  0:06:41s\n",
      "epoch 28 | loss: 0.85558 |  0:06:53s\n",
      "epoch 29 | loss: 0.85412 |  0:07:05s\n",
      "epoch 30 | loss: 0.85291 |  0:07:17s\n",
      "epoch 31 | loss: 0.85221 |  0:07:30s\n",
      "epoch 32 | loss: 0.85065 |  0:07:42s\n",
      "epoch 33 | loss: 0.84642 |  0:07:55s\n",
      "epoch 34 | loss: 0.84193 |  0:08:07s\n",
      "epoch 35 | loss: 0.83844 |  0:08:19s\n",
      "epoch 36 | loss: 0.83568 |  0:08:31s\n",
      "epoch 37 | loss: 0.83198 |  0:08:43s\n",
      "epoch 38 | loss: 0.82862 |  0:08:55s\n",
      "epoch 39 | loss: 0.82724 |  0:09:07s\n",
      "epoch 40 | loss: 0.82393 |  0:09:19s\n",
      "epoch 41 | loss: 0.82177 |  0:09:35s\n",
      "epoch 42 | loss: 0.81999 |  0:09:47s\n",
      "epoch 43 | loss: 0.81684 |  0:10:00s\n",
      "epoch 44 | loss: 0.81467 |  0:10:24s\n",
      "epoch 45 | loss: 0.81026 |  0:10:37s\n",
      "epoch 46 | loss: 0.80605 |  0:11:06s\n",
      "epoch 47 | loss: 0.8034  |  0:11:22s\n",
      "epoch 48 | loss: 0.79905 |  0:11:35s\n",
      "epoch 49 | loss: 0.79589 |  0:11:50s\n",
      "epoch 50 | loss: 0.79224 |  0:12:30s\n",
      "epoch 51 | loss: 0.78834 |  0:12:44s\n",
      "epoch 52 | loss: 0.78432 |  0:12:57s\n",
      "epoch 53 | loss: 0.78063 |  0:13:10s\n",
      "epoch 54 | loss: 0.77617 |  0:13:22s\n",
      "epoch 55 | loss: 0.77184 |  0:13:38s\n",
      "epoch 56 | loss: 0.76906 |  0:13:52s\n",
      "epoch 57 | loss: 0.76539 |  0:14:06s\n",
      "epoch 58 | loss: 0.76274 |  0:14:22s\n",
      "epoch 59 | loss: 0.759   |  0:14:36s\n",
      "epoch 60 | loss: 0.75785 |  0:14:50s\n",
      "epoch 61 | loss: 0.75359 |  0:15:05s\n",
      "epoch 62 | loss: 0.75102 |  0:15:20s\n",
      "epoch 63 | loss: 0.74805 |  0:15:34s\n",
      "epoch 64 | loss: 0.73962 |  0:15:48s\n",
      "epoch 65 | loss: 0.72476 |  0:16:03s\n",
      "epoch 66 | loss: 0.70664 |  0:16:17s\n",
      "epoch 67 | loss: 0.68679 |  0:16:31s\n",
      "epoch 68 | loss: 0.66633 |  0:16:46s\n",
      "epoch 69 | loss: 0.64263 |  0:17:00s\n",
      "epoch 70 | loss: 0.61953 |  0:17:14s\n",
      "epoch 71 | loss: 0.59572 |  0:17:29s\n",
      "epoch 72 | loss: 0.57356 |  0:17:43s\n",
      "epoch 73 | loss: 0.55041 |  0:17:57s\n",
      "epoch 74 | loss: 0.53031 |  0:18:11s\n",
      "epoch 75 | loss: 0.50875 |  0:18:25s\n",
      "epoch 76 | loss: 0.48817 |  0:18:41s\n",
      "epoch 77 | loss: 0.46923 |  0:18:55s\n",
      "epoch 78 | loss: 0.45255 |  0:19:18s\n",
      "epoch 79 | loss: 0.43662 |  0:19:57s\n",
      "epoch 80 | loss: 0.4202  |  0:20:18s\n",
      "epoch 81 | loss: 0.40541 |  0:20:41s\n",
      "epoch 82 | loss: 0.39122 |  0:20:55s\n",
      "epoch 83 | loss: 0.3786  |  0:21:10s\n",
      "epoch 84 | loss: 0.36724 |  0:21:24s\n",
      "epoch 85 | loss: 0.3566  |  0:21:39s\n",
      "epoch 86 | loss: 0.34723 |  0:21:53s\n",
      "epoch 87 | loss: 0.33827 |  0:22:08s\n",
      "epoch 88 | loss: 0.33049 |  0:22:22s\n",
      "epoch 89 | loss: 0.3224  |  0:22:37s\n"
     ]
    }
   ],
   "source": [
    "# pretrain model\n",
    "unsupervised_model = TabNetPretrainer(\n",
    "    cat_idxs=cat_col_idx,\n",
    "    cat_dims=cat_col_dims,\n",
    "    cat_emb_dim=[int(round(np.sqrt(i)/4,0))+1 for i in cat_col_dims],\n",
    "    optimizer_fn=torch.optim.Adam,\n",
    "    optimizer_params=dict(lr=5*1e-3),\n",
    "    scheduler_params={'is_batch_level': True, 'T_0':10, 'T_mult':2, 'eta_min': 0.001},\n",
    "    scheduler_fn=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts,\n",
    "    mask_type='entmax'\n",
    ")\n",
    "\n",
    "unsupervised_model.fit(\n",
    "    X_train=x_sme,\n",
    "    max_epochs=90,\n",
    "    drop_last=False,\n",
    "    pretraining_ratio=0.6, #0.5\n",
    ")\n",
    "\n",
    "reconstructed_X, embedded_X = unsupervised_model.predict(x_sme)\n",
    "assert(reconstructed_X.shape == embedded_X.shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device used : cpu\n"
     ]
    }
   ],
   "source": [
    "model = TabNetClassifier(\n",
    "    cat_idxs=cat_col_idx,\n",
    "    cat_dims=cat_col_dims,\n",
    "    cat_emb_dim=[int(round(np.sqrt(i)/4,0))+1 for i in cat_col_dims],\n",
    "    optimizer_fn=torch.optim.Adam,\n",
    "    optimizer_params=dict(lr=1e-3),\n",
    "    scheduler_params={'is_batch_level': True, 'T_0':10, 'T_mult':2, 'eta_min': 0.001},\n",
    "    scheduler_fn=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts,\n",
    "    mask_type='sparsemax',\n",
    "    gamma=1.3,\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading weights from unsupervised pretraining\n",
      "epoch 0  | loss: 1.56516 | train_balanced_accuracy: 0.75936 | train_accuracy: 0.75292 |  0:00:13s\n",
      "epoch 1  | loss: 0.606   | train_balanced_accuracy: 0.77399 | train_accuracy: 0.77424 |  0:00:27s\n",
      "epoch 2  | loss: 0.53954 | train_balanced_accuracy: 0.80391 | train_accuracy: 0.80359 |  0:00:40s\n",
      "epoch 3  | loss: 0.45417 | train_balanced_accuracy: 0.85557 | train_accuracy: 0.85688 |  0:00:53s\n",
      "epoch 4  | loss: 0.35965 | train_balanced_accuracy: 0.90157 | train_accuracy: 0.90079 |  0:01:07s\n",
      "epoch 5  | loss: 0.29062 | train_balanced_accuracy: 0.92428 | train_accuracy: 0.9252  |  0:01:21s\n",
      "epoch 6  | loss: 0.23819 | train_balanced_accuracy: 0.93739 | train_accuracy: 0.93777 |  0:01:36s\n",
      "epoch 7  | loss: 0.20229 | train_balanced_accuracy: 0.94901 | train_accuracy: 0.94932 |  0:01:49s\n",
      "epoch 8  | loss: 0.17825 | train_balanced_accuracy: 0.95247 | train_accuracy: 0.95145 |  0:02:02s\n",
      "epoch 9  | loss: 0.16044 | train_balanced_accuracy: 0.95957 | train_accuracy: 0.96026 |  0:02:16s\n",
      "epoch 10 | loss: 0.14514 | train_balanced_accuracy: 0.96242 | train_accuracy: 0.96232 |  0:02:30s\n",
      "epoch 11 | loss: 0.13442 | train_balanced_accuracy: 0.96656 | train_accuracy: 0.96696 |  0:02:43s\n",
      "epoch 12 | loss: 0.12305 | train_balanced_accuracy: 0.96688 | train_accuracy: 0.96676 |  0:02:57s\n",
      "epoch 13 | loss: 0.11487 | train_balanced_accuracy: 0.97137 | train_accuracy: 0.97142 |  0:03:10s\n",
      "epoch 14 | loss: 0.1089  | train_balanced_accuracy: 0.97339 | train_accuracy: 0.97376 |  0:03:23s\n",
      "epoch 15 | loss: 0.10419 | train_balanced_accuracy: 0.97466 | train_accuracy: 0.9752  |  0:03:37s\n",
      "epoch 16 | loss: 0.09607 | train_balanced_accuracy: 0.97565 | train_accuracy: 0.97552 |  0:03:50s\n",
      "epoch 17 | loss: 0.09447 | train_balanced_accuracy: 0.97806 | train_accuracy: 0.97773 |  0:04:04s\n",
      "epoch 18 | loss: 0.08782 | train_balanced_accuracy: 0.97942 | train_accuracy: 0.97945 |  0:04:18s\n",
      "epoch 19 | loss: 0.08427 | train_balanced_accuracy: 0.98088 | train_accuracy: 0.98092 |  0:04:31s\n",
      "epoch 20 | loss: 0.07813 | train_balanced_accuracy: 0.98205 | train_accuracy: 0.98194 |  0:04:44s\n",
      "epoch 21 | loss: 0.07548 | train_balanced_accuracy: 0.98255 | train_accuracy: 0.98251 |  0:04:58s\n",
      "epoch 22 | loss: 0.07237 | train_balanced_accuracy: 0.98295 | train_accuracy: 0.98278 |  0:05:11s\n",
      "epoch 23 | loss: 0.07235 | train_balanced_accuracy: 0.98274 | train_accuracy: 0.98293 |  0:05:25s\n",
      "epoch 24 | loss: 0.06538 | train_balanced_accuracy: 0.98429 | train_accuracy: 0.98441 |  0:05:38s\n",
      "epoch 25 | loss: 0.06295 | train_balanced_accuracy: 0.98603 | train_accuracy: 0.98603 |  0:05:52s\n",
      "epoch 26 | loss: 0.06121 | train_balanced_accuracy: 0.98545 | train_accuracy: 0.98589 |  0:06:06s\n",
      "epoch 27 | loss: 0.05971 | train_balanced_accuracy: 0.98665 | train_accuracy: 0.98666 |  0:06:19s\n",
      "epoch 28 | loss: 0.0573  | train_balanced_accuracy: 0.98572 | train_accuracy: 0.98609 |  0:06:33s\n",
      "epoch 29 | loss: 0.05494 | train_balanced_accuracy: 0.98808 | train_accuracy: 0.98795 |  0:06:46s\n",
      "epoch 30 | loss: 0.05283 | train_balanced_accuracy: 0.98873 | train_accuracy: 0.98872 |  0:06:59s\n",
      "epoch 31 | loss: 0.05131 | train_balanced_accuracy: 0.98915 | train_accuracy: 0.98893 |  0:07:12s\n",
      "epoch 32 | loss: 0.04849 | train_balanced_accuracy: 0.98968 | train_accuracy: 0.98964 |  0:07:26s\n",
      "epoch 33 | loss: 0.04949 | train_balanced_accuracy: 0.98901 | train_accuracy: 0.98856 |  0:07:39s\n",
      "epoch 34 | loss: 0.04569 | train_balanced_accuracy: 0.99001 | train_accuracy: 0.99004 |  0:07:53s\n",
      "epoch 35 | loss: 0.04796 | train_balanced_accuracy: 0.99057 | train_accuracy: 0.99015 |  0:08:06s\n",
      "epoch 36 | loss: 0.04284 | train_balanced_accuracy: 0.99125 | train_accuracy: 0.99093 |  0:08:19s\n",
      "epoch 37 | loss: 0.04227 | train_balanced_accuracy: 0.99084 | train_accuracy: 0.99104 |  0:08:33s\n",
      "epoch 38 | loss: 0.03977 | train_balanced_accuracy: 0.99175 | train_accuracy: 0.99143 |  0:08:46s\n",
      "epoch 39 | loss: 0.03982 | train_balanced_accuracy: 0.99158 | train_accuracy: 0.99124 |  0:09:00s\n",
      "epoch 40 | loss: 0.03842 | train_balanced_accuracy: 0.9914  | train_accuracy: 0.99156 |  0:09:13s\n",
      "epoch 41 | loss: 0.03848 | train_balanced_accuracy: 0.99281 | train_accuracy: 0.99283 |  0:09:27s\n",
      "epoch 42 | loss: 0.0368  | train_balanced_accuracy: 0.9929  | train_accuracy: 0.99294 |  0:09:40s\n",
      "epoch 43 | loss: 0.0358  | train_balanced_accuracy: 0.99306 | train_accuracy: 0.99291 |  0:09:53s\n",
      "epoch 44 | loss: 0.03391 | train_balanced_accuracy: 0.99249 | train_accuracy: 0.9924  |  0:10:07s\n",
      "epoch 45 | loss: 0.03391 | train_balanced_accuracy: 0.99267 | train_accuracy: 0.99278 |  0:10:20s\n",
      "epoch 46 | loss: 0.03251 | train_balanced_accuracy: 0.99316 | train_accuracy: 0.99328 |  0:10:34s\n",
      "epoch 47 | loss: 0.03186 | train_balanced_accuracy: 0.99279 | train_accuracy: 0.99285 |  0:10:47s\n",
      "epoch 48 | loss: 0.03276 | train_balanced_accuracy: 0.99408 | train_accuracy: 0.99405 |  0:11:00s\n",
      "epoch 49 | loss: 0.03214 | train_balanced_accuracy: 0.99397 | train_accuracy: 0.994   |  0:11:14s\n",
      "Stop training because you reached max_epochs = 50 with best_epoch = 48 and best_train_accuracy = 0.99405\n",
      "Best weights from best epoch are automatically used!\n"
     ]
    }
   ],
   "source": [
    "model.fit(\n",
    "    X_train=x_sme,\n",
    "    y_train=y_sme,\n",
    "    eval_set=[(x_sme, y_sme)],\n",
    "    eval_name=['train'],\n",
    "    eval_metric=['balanced_accuracy', 'accuracy'],\n",
    "    max_epochs=50,\n",
    "    patience=5,\n",
    "    weights=0,  # 0: no, 1: balanced, dict: customized\n",
    "    batch_size=512,\n",
    "    virtual_batch_size=128,\n",
    "    num_workers=0,\n",
    "    drop_last=False,\n",
    "    from_unsupervised=unsupervised_model,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Result"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Customer_ID :  0.781\n",
      "Month :  0.042\n",
      "Age :  0.001\n",
      "Monthly_Inhand_Salary :  0.005\n",
      "Num_Bank_Accounts :  0.003\n",
      "Num_Credit_Card :  0.004\n",
      "Interest_Rate :  0.005\n",
      "Num_of_Loan :  0.024\n",
      "Delay_from_due_date :  0.009\n",
      "Num_of_Delayed_Payment :  0.017\n",
      "Changed_Credit_Limit :  0.012\n",
      "Num_Credit_Inquiries :  0.013\n",
      "Credit_Mix :  0.027\n",
      "Outstanding_Debt :  0.033\n",
      "Credit_Utilization_Ratio :  0.001\n",
      "Credit_History_Age :  0.009\n",
      "Payment_of_Min_Amount :  0.009\n",
      "Total_EMI_per_month :  0.0\n",
      "Amount_invested_monthly :  0.001\n",
      "Payment_Behaviour :  0.004\n",
      "Monthly_Balance :  0.0\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(all_col_list)):\n",
    "    print(all_col_list[i], ': ', model.feature_importances_.round(3)[i])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.99      0.91     21782\n",
      "           1       0.99      0.85      0.91     40214\n",
      "           2       0.85      0.97      0.90     13004\n",
      "\n",
      "    accuracy                           0.91     75000\n",
      "   macro avg       0.89      0.94      0.91     75000\n",
      "weighted avg       0.92      0.91      0.91     75000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_true=y_train, y_pred=model.predict(x_train)))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "outputs": [],
   "source": [
    "# f1_score(y_train, (model.predict(x_train)))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "outputs": [],
   "source": [
    "predicted = model.predict(x_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7193329538527407\n",
      "0.72\n"
     ]
    }
   ],
   "source": [
    "print(f1_score(y_test, predicted, average='weighted'))\n",
    "print(accuracy_score(y_test, predicted))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.80      0.75      7216\n",
      "           1       0.75      0.70      0.72     12960\n",
      "           2       0.68      0.66      0.67      4824\n",
      "\n",
      "    accuracy                           0.72     25000\n",
      "   macro avg       0.71      0.72      0.71     25000\n",
      "weighted avg       0.72      0.72      0.72     25000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, predicted))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "기존 대비 0번 클래스를 더 잘맞추나, 2번 클래스에 대한 전반적인 성능은 줄었음"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5798 1385   33]\n",
      " [2448 9029 1483]\n",
      " [  62 1589 3173]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, predicted))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading weights from unsupervised pretraining\n",
      "epoch 0  | loss: 1.40156 | train_balanced_accuracy: 0.76549 | train_accuracy: 0.75571 |  0:00:17s\n",
      "epoch 1  | loss: 0.60832 | train_balanced_accuracy: 0.78071 | train_accuracy: 0.7718  |  0:00:31s\n",
      "epoch 2  | loss: 0.54666 | train_balanced_accuracy: 0.80406 | train_accuracy: 0.79757 |  0:00:46s\n",
      "epoch 3  | loss: 0.46874 | train_balanced_accuracy: 0.83279 | train_accuracy: 0.82258 |  0:01:00s\n",
      "epoch 4  | loss: 0.38928 | train_balanced_accuracy: 0.88056 | train_accuracy: 0.87396 |  0:01:14s\n",
      "epoch 5  | loss: 0.31015 | train_balanced_accuracy: 0.91282 | train_accuracy: 0.90991 |  0:01:31s\n",
      "epoch 6  | loss: 0.25004 | train_balanced_accuracy: 0.93238 | train_accuracy: 0.92986 |  0:01:43s\n",
      "epoch 7  | loss: 0.21416 | train_balanced_accuracy: 0.94273 | train_accuracy: 0.93966 |  0:01:58s\n",
      "epoch 8  | loss: 0.18589 | train_balanced_accuracy: 0.95166 | train_accuracy: 0.95021 |  0:02:14s\n",
      "epoch 9  | loss: 0.16355 | train_balanced_accuracy: 0.95931 | train_accuracy: 0.95767 |  0:02:33s\n",
      "epoch 10 | loss: 0.1446  | train_balanced_accuracy: 0.96363 | train_accuracy: 0.96264 |  0:02:47s\n",
      "epoch 11 | loss: 0.13338 | train_balanced_accuracy: 0.9652  | train_accuracy: 0.96374 |  0:03:03s\n",
      "epoch 12 | loss: 0.12609 | train_balanced_accuracy: 0.96894 | train_accuracy: 0.96752 |  0:03:18s\n",
      "epoch 13 | loss: 0.11324 | train_balanced_accuracy: 0.9714  | train_accuracy: 0.97054 |  0:03:33s\n",
      "epoch 14 | loss: 0.10511 | train_balanced_accuracy: 0.97361 | train_accuracy: 0.97261 |  0:03:49s\n",
      "epoch 15 | loss: 0.09907 | train_balanced_accuracy: 0.97527 | train_accuracy: 0.97422 |  0:04:04s\n",
      "epoch 16 | loss: 0.09589 | train_balanced_accuracy: 0.97709 | train_accuracy: 0.97625 |  0:04:19s\n",
      "epoch 17 | loss: 0.08814 | train_balanced_accuracy: 0.97704 | train_accuracy: 0.97622 |  0:04:33s\n",
      "epoch 18 | loss: 0.08522 | train_balanced_accuracy: 0.97926 | train_accuracy: 0.97879 |  0:04:47s\n",
      "epoch 19 | loss: 0.08084 | train_balanced_accuracy: 0.98063 | train_accuracy: 0.9801  |  0:05:01s\n",
      "epoch 20 | loss: 0.07362 | train_balanced_accuracy: 0.98177 | train_accuracy: 0.98101 |  0:05:14s\n",
      "epoch 21 | loss: 0.07383 | train_balanced_accuracy: 0.98178 | train_accuracy: 0.98105 |  0:05:28s\n",
      "epoch 22 | loss: 0.06947 | train_balanced_accuracy: 0.98379 | train_accuracy: 0.98307 |  0:05:41s\n",
      "epoch 23 | loss: 0.06425 | train_balanced_accuracy: 0.98252 | train_accuracy: 0.98157 |  0:05:55s\n",
      "epoch 24 | loss: 0.06797 | train_balanced_accuracy: 0.98426 | train_accuracy: 0.98352 |  0:06:08s\n",
      "epoch 25 | loss: 0.0622  | train_balanced_accuracy: 0.98455 | train_accuracy: 0.98367 |  0:06:22s\n",
      "epoch 26 | loss: 0.0595  | train_balanced_accuracy: 0.98553 | train_accuracy: 0.98492 |  0:06:36s\n",
      "epoch 27 | loss: 0.05763 | train_balanced_accuracy: 0.98589 | train_accuracy: 0.98489 |  0:06:51s\n",
      "epoch 28 | loss: 0.05537 | train_balanced_accuracy: 0.98658 | train_accuracy: 0.98564 |  0:07:05s\n",
      "epoch 29 | loss: 0.05348 | train_balanced_accuracy: 0.98686 | train_accuracy: 0.98658 |  0:07:18s\n",
      "epoch 30 | loss: 0.05142 | train_balanced_accuracy: 0.98736 | train_accuracy: 0.98703 |  0:07:32s\n",
      "epoch 31 | loss: 0.0509  | train_balanced_accuracy: 0.98792 | train_accuracy: 0.98773 |  0:07:45s\n",
      "epoch 32 | loss: 0.05104 | train_balanced_accuracy: 0.98842 | train_accuracy: 0.98787 |  0:07:59s\n",
      "epoch 33 | loss: 0.04675 | train_balanced_accuracy: 0.98977 | train_accuracy: 0.98931 |  0:08:12s\n",
      "epoch 34 | loss: 0.04543 | train_balanced_accuracy: 0.98938 | train_accuracy: 0.9886  |  0:08:26s\n",
      "epoch 35 | loss: 0.04336 | train_balanced_accuracy: 0.9902  | train_accuracy: 0.98974 |  0:08:40s\n",
      "epoch 36 | loss: 0.0418  | train_balanced_accuracy: 0.98911 | train_accuracy: 0.98809 |  0:08:53s\n",
      "epoch 37 | loss: 0.04218 | train_balanced_accuracy: 0.991   | train_accuracy: 0.9907  |  0:09:07s\n",
      "epoch 38 | loss: 0.043   | train_balanced_accuracy: 0.99056 | train_accuracy: 0.99012 |  0:09:21s\n",
      "epoch 39 | loss: 0.04118 | train_balanced_accuracy: 0.99115 | train_accuracy: 0.99097 |  0:09:34s\n",
      "epoch 40 | loss: 0.03804 | train_balanced_accuracy: 0.99108 | train_accuracy: 0.99026 |  0:09:48s\n",
      "epoch 41 | loss: 0.03936 | train_balanced_accuracy: 0.99081 | train_accuracy: 0.9902  |  0:10:02s\n",
      "epoch 42 | loss: 0.03805 | train_balanced_accuracy: 0.9914  | train_accuracy: 0.99089 |  0:10:15s\n",
      "epoch 43 | loss: 0.03947 | train_balanced_accuracy: 0.99162 | train_accuracy: 0.99102 |  0:10:29s\n",
      "epoch 44 | loss: 0.03608 | train_balanced_accuracy: 0.99227 | train_accuracy: 0.99172 |  0:10:42s\n",
      "epoch 45 | loss: 0.03519 | train_balanced_accuracy: 0.99251 | train_accuracy: 0.99208 |  0:10:56s\n",
      "epoch 46 | loss: 0.03493 | train_balanced_accuracy: 0.99225 | train_accuracy: 0.99198 |  0:11:09s\n",
      "epoch 47 | loss: 0.03401 | train_balanced_accuracy: 0.99294 | train_accuracy: 0.99258 |  0:11:23s\n",
      "epoch 48 | loss: 0.03308 | train_balanced_accuracy: 0.99303 | train_accuracy: 0.99275 |  0:11:36s\n",
      "epoch 49 | loss: 0.03274 | train_balanced_accuracy: 0.9933  | train_accuracy: 0.99301 |  0:11:50s\n",
      "Stop training because you reached max_epochs = 50 with best_epoch = 49 and best_train_accuracy = 0.99301\n",
      "Best weights from best epoch are automatically used!\n"
     ]
    }
   ],
   "source": [
    "model.fit(\n",
    "    X_train=x_sme,\n",
    "    y_train=y_sme,\n",
    "    eval_set=[(x_sme, y_sme)],\n",
    "    eval_name=['train'],\n",
    "    eval_metric=['balanced_accuracy', 'accuracy'],\n",
    "    max_epochs=50,\n",
    "    patience=5,\n",
    "    weights=1,  # 0: no, 1: balanced, dict: customized\n",
    "    batch_size=512,\n",
    "    virtual_batch_size=128,\n",
    "    num_workers=0,\n",
    "    drop_last=False,\n",
    "    from_unsupervised=unsupervised_model,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Result"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Customer_ID :  0.761\n",
      "Month :  0.044\n",
      "Age :  0.007\n",
      "Monthly_Inhand_Salary :  0.022\n",
      "Num_Bank_Accounts :  0.001\n",
      "Num_Credit_Card :  0.001\n",
      "Interest_Rate :  0.007\n",
      "Num_of_Loan :  0.027\n",
      "Delay_from_due_date :  0.005\n",
      "Num_of_Delayed_Payment :  0.015\n",
      "Changed_Credit_Limit :  0.016\n",
      "Num_Credit_Inquiries :  0.021\n",
      "Credit_Mix :  0.02\n",
      "Outstanding_Debt :  0.028\n",
      "Credit_Utilization_Ratio :  0.0\n",
      "Credit_History_Age :  0.009\n",
      "Payment_of_Min_Amount :  0.008\n",
      "Total_EMI_per_month :  0.0\n",
      "Amount_invested_monthly :  0.001\n",
      "Payment_Behaviour :  0.008\n",
      "Monthly_Balance :  0.001\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(all_col_list)):\n",
    "    print(all_col_list[i], ': ', model.feature_importances_.round(3)[i])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91     21782\n",
      "           1       0.99      0.84      0.91     40214\n",
      "           2       0.85      0.97      0.90     13004\n",
      "\n",
      "    accuracy                           0.91     75000\n",
      "   macro avg       0.89      0.94      0.91     75000\n",
      "weighted avg       0.92      0.91      0.91     75000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_true=y_train, y_pred=model.predict(x_train)))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "outputs": [],
   "source": [
    "# f1_score(y_train, (model.predict(x_train)))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "outputs": [],
   "source": [
    "predicted = model.predict(x_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7187896178339925\n",
      "0.71964\n"
     ]
    }
   ],
   "source": [
    "print(f1_score(y_test, predicted, average='weighted'))\n",
    "print(accuracy_score(y_test, predicted))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.82      0.75      7216\n",
      "           1       0.76      0.69      0.72     12960\n",
      "           2       0.67      0.66      0.66      4824\n",
      "\n",
      "    accuracy                           0.72     25000\n",
      "   macro avg       0.71      0.72      0.71     25000\n",
      "weighted avg       0.72      0.72      0.72     25000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, predicted))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "기존 대비 0번 클래스를 더 잘맞추나, 2번 클래스에 대한 전반적인 성능은 줄었음"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5887 1293   36]\n",
      " [2513 8926 1521]\n",
      " [  61 1585 3178]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, predicted))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "outputs": [
    {
     "data": {
      "text/plain": "array([0.90526048, 1.5942762 , 0.7885803 ])"
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### RandomForest"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier(n_estimators=400, class_weight='balanced_subsample', max_depth=25, n_jobs=-1, random_state=42)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "outputs": [
    {
     "data": {
      "text/plain": "RandomForestClassifier(class_weight='balanced_subsample', max_depth=25,\n                       n_estimators=400, n_jobs=-1, random_state=42)",
      "text/html": "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(class_weight=&#x27;balanced_subsample&#x27;, max_depth=25,\n                       n_estimators=400, n_jobs=-1, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(class_weight=&#x27;balanced_subsample&#x27;, max_depth=25,\n                       n_estimators=400, n_jobs=-1, random_state=42)</pre></div></div></div></div></div>"
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc.fit(x_sme, y_sme)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "outputs": [],
   "source": [
    "y_pred = rfc.predict(x_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "outputs": [
    {
     "data": {
      "text/plain": "0.9031466666666667"
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_true=y_train, y_pred=rfc.predict(x_train))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.80      0.76      7216\n",
      "           1       0.79      0.67      0.72     12960\n",
      "           2       0.60      0.73      0.66      4824\n",
      "\n",
      "    accuracy                           0.72     25000\n",
      "   macro avg       0.70      0.73      0.71     25000\n",
      "weighted avg       0.73      0.72      0.72     25000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_true=y_test, y_pred=y_pred))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5794 1102  320]\n",
      " [2294 8640 2026]\n",
      " [  41 1252 3531]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, y_pred))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Combination of Over- and Under-sampling (Manual)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import EditedNearestNeighbours\n",
    "from imblearn.over_sampling import BorderlineSMOTE\n",
    "\n",
    "from imblearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(n_estimators=700, class_weight='balanced_subsample', n_jobs=-1, random_state=42)\n",
    "\n",
    "bsmote = BorderlineSMOTE(random_state=42, k_neighbors=7, n_jobs=-1)\n",
    "enn = EditedNearestNeighbours(kind_sel='mode', n_jobs=-1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "outputs": [],
   "source": [
    "pipeline = Pipeline(steps=[('o', bsmote), ('u', enn), ('m', model)])\n",
    "cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=3, random_state=42)\n",
    "# scores = cross_val_score(pipeline, x_train, y_train, scoring='accuracy', cv=cv)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "outputs": [
    {
     "data": {
      "text/plain": "Pipeline(steps=[('o',\n                 BorderlineSMOTE(k_neighbors=7, n_jobs=-1, random_state=42)),\n                ('u', EditedNearestNeighbours(kind_sel='mode', n_jobs=-1)),\n                ('m',\n                 RandomForestClassifier(class_weight='balanced_subsample',\n                                        n_estimators=700, n_jobs=-1,\n                                        random_state=42))])",
      "text/html": "<style>#sk-container-id-6 {color: black;background-color: white;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;o&#x27;,\n                 BorderlineSMOTE(k_neighbors=7, n_jobs=-1, random_state=42)),\n                (&#x27;u&#x27;, EditedNearestNeighbours(kind_sel=&#x27;mode&#x27;, n_jobs=-1)),\n                (&#x27;m&#x27;,\n                 RandomForestClassifier(class_weight=&#x27;balanced_subsample&#x27;,\n                                        n_estimators=700, n_jobs=-1,\n                                        random_state=42))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;o&#x27;,\n                 BorderlineSMOTE(k_neighbors=7, n_jobs=-1, random_state=42)),\n                (&#x27;u&#x27;, EditedNearestNeighbours(kind_sel=&#x27;mode&#x27;, n_jobs=-1)),\n                (&#x27;m&#x27;,\n                 RandomForestClassifier(class_weight=&#x27;balanced_subsample&#x27;,\n                                        n_estimators=700, n_jobs=-1,\n                                        random_state=42))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">BorderlineSMOTE</label><div class=\"sk-toggleable__content\"><pre>BorderlineSMOTE(k_neighbors=7, n_jobs=-1, random_state=42)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">EditedNearestNeighbours</label><div class=\"sk-toggleable__content\"><pre>EditedNearestNeighbours(kind_sel=&#x27;mode&#x27;, n_jobs=-1)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(class_weight=&#x27;balanced_subsample&#x27;, n_estimators=700,\n                       n_jobs=-1, random_state=42)</pre></div></div></div></div></div></div></div>"
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.fit(x_train, y_train)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "outputs": [],
   "source": [
    "y_pred = pipeline.predict(x_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "outputs": [
    {
     "data": {
      "text/plain": "0.7246"
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.82      0.76      7216\n",
      "           1       0.80      0.66      0.72     12960\n",
      "           2       0.62      0.76      0.68      4824\n",
      "\n",
      "    accuracy                           0.72     25000\n",
      "   macro avg       0.71      0.75      0.72     25000\n",
      "weighted avg       0.74      0.72      0.72     25000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "outputs": [],
   "source": [
    "def hybrid_sampling_and_classification(over_sampler, under_sampler, clf, X, y):\n",
    "    \"\"\"\n",
    "    :param over_sample: 생성된 oversampling 객체\n",
    "    :param under_sampler: 생성된 undersampling 객체\n",
    "    :param clf: 분류기\n",
    "    :return: pipeline 객체\n",
    "    \"\"\"\n",
    "\n",
    "    from imblearn.pipeline import Pipeline\n",
    "    pipeline = Pipeline(steps=[('o', over_sampler), ('u', under_sampler), ('m', clf)])\n",
    "    pipeline.fit(X, y)\n",
    "\n",
    "    return pipeline"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "outputs": [],
   "source": [
    "pipeline = hybrid_sampling_and_classification(bsmote, enn, model, x_train, y_train)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "outputs": [],
   "source": [
    "y_pred = pipeline.predict(x_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "outputs": [
    {
     "data": {
      "text/plain": "0.7246"
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "outputs": [],
   "source": [
    "y_pred_train = pipeline.predict(x_train)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "outputs": [
    {
     "data": {
      "text/plain": "0.9092666666666667"
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_train, y_pred_train)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "outputs": [
    {
     "data": {
      "text/plain": "Counter({2: 13004, 1: 40214, 0: 21782})"
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "Counter(y_train)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(n_estimators=700, class_weight='balanced_subsample', n_jobs=-1, random_state=42)\n",
    "\n",
    "bsmote = BorderlineSMOTE(sampling_strategy={0: 25000, 1: 40214, 2: 20000}, random_state=42, k_neighbors=7, n_jobs=-1)\n",
    "enn = EditedNearestNeighbours(kind_sel='mode', n_jobs=-1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "outputs": [],
   "source": [
    "pipeline = hybrid_sampling_and_classification(bsmote, enn, model, x_train, y_train)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "outputs": [],
   "source": [
    "y_pred = pipeline.predict(x_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "outputs": [
    {
     "data": {
      "text/plain": "0.73468"
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "outputs": [],
   "source": [
    "def show_results(pipeline, x_train, y_train, x_test, y_test):\n",
    "    \"\"\"\n",
    "\n",
    "    :param pipeline: learned object\n",
    "    :param x_train: x train input\n",
    "    :param y_train: y train\n",
    "    :param x_test: x test input\n",
    "    :param y_test: y test\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "    y_train_pred = pipeline.predict(x_train)\n",
    "    y_test_pred = pipeline.predict(x_test)\n",
    "\n",
    "    print('Accuracy Score (Train): ', accuracy_score(y_train, y_train_pred))\n",
    "    print('Accuracy Score (Test): ', accuracy_score(y_test, y_test_pred))\n",
    "\n",
    "    print('Classification Report....: ')\n",
    "    print(classification_report(y_test, y_test_pred))\n",
    "\n",
    "    print('Confusion Matrix...: ')\n",
    "    print(confusion_matrix(y_test, y_test_pred))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score (Train):  0.9078133333333334\n",
      "Accuracy Score (Test):  0.73468\n",
      "Classification Report....: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.80      0.76      7216\n",
      "           1       0.79      0.69      0.73     12960\n",
      "           2       0.65      0.76      0.70      4824\n",
      "\n",
      "    accuracy                           0.73     25000\n",
      "   macro avg       0.72      0.75      0.73     25000\n",
      "weighted avg       0.74      0.73      0.73     25000\n",
      "\n",
      "Confusion Matrix...: \n",
      "[[5801 1257  158]\n",
      " [2248 8923 1789]\n",
      " [  33 1148 3643]]\n"
     ]
    }
   ],
   "source": [
    "show_results(pipeline, x_train, y_train, x_test, y_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## SMOTE NC + ENN + Cost Sensitive\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTENC"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "outputs": [],
   "source": [
    "cat_col_idx = [0, 1, 12, 15, 16, 19]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(n_estimators=1000, class_weight='balanced_subsample', n_jobs=-1, random_state=42)\n",
    "\n",
    "smoteen = SMOTENC(random_state=42, categorical_features=cat_col_idx, sampling_strategy={0: 25000, 1: 40214, 2: 20000})\n",
    "enn = EditedNearestNeighbours(kind_sel='mode', n_jobs=-1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "outputs": [],
   "source": [
    "pipeline = hybrid_sampling_and_classification(smoteen, enn, model, x_train, y_train)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score (Train):  0.9076533333333333\n",
      "Accuracy Score (Test):  0.73808\n",
      "Classification Report....: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.80      0.76      7216\n",
      "           1       0.78      0.70      0.74     12960\n",
      "           2       0.67      0.75      0.71      4824\n",
      "\n",
      "    accuracy                           0.74     25000\n",
      "   macro avg       0.72      0.75      0.74     25000\n",
      "weighted avg       0.74      0.74      0.74     25000\n",
      "\n",
      "Confusion Matrix...: \n",
      "[[5801 1312  103]\n",
      " [2259 9017 1684]\n",
      " [  28 1162 3634]]\n"
     ]
    }
   ],
   "source": [
    "show_results(pipeline, x_train, y_train, x_test, y_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(n_estimators=1000, class_weight='balanced_subsample', n_jobs=-1, random_state=42)\n",
    "\n",
    "smoteen = SMOTENC(random_state=42, categorical_features=cat_col_idx)\n",
    "enn = EditedNearestNeighbours(kind_sel='mode', n_jobs=-1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "outputs": [],
   "source": [
    "pipeline = hybrid_sampling_and_classification(smoteen, enn, model, x_train, y_train)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score (Train):  0.91084\n",
      "Accuracy Score (Test):  0.73628\n",
      "Classification Report....: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.85      0.77      7216\n",
      "           1       0.80      0.67      0.73     12960\n",
      "           2       0.66      0.74      0.70      4824\n",
      "\n",
      "    accuracy                           0.74     25000\n",
      "   macro avg       0.72      0.75      0.73     25000\n",
      "weighted avg       0.75      0.74      0.74     25000\n",
      "\n",
      "Confusion Matrix...: \n",
      "[[6108  989  119]\n",
      " [2520 8708 1732]\n",
      " [  40 1193 3591]]\n"
     ]
    }
   ],
   "source": [
    "show_results(pipeline, x_train, y_train, x_test, y_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(n_estimators=1000, class_weight='balanced_subsample', n_jobs=-1, random_state=42)\n",
    "\n",
    "smoteen = SMOTENC(random_state=42, categorical_features=cat_col_idx, sampling_strategy={0: 25000, 1: 40214, 2: 25000})\n",
    "enn = EditedNearestNeighbours(kind_sel='mode', n_jobs=-1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "outputs": [],
   "source": [
    "pipeline = hybrid_sampling_and_classification(smoteen, enn, model, x_train, y_train)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score (Train):  0.9113733333333334\n",
      "Accuracy Score (Test):  0.73872\n",
      "Classification Report....: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.84      0.77      7216\n",
      "           1       0.79      0.69      0.74     12960\n",
      "           2       0.67      0.72      0.70      4824\n",
      "\n",
      "    accuracy                           0.74     25000\n",
      "   macro avg       0.72      0.75      0.73     25000\n",
      "weighted avg       0.74      0.74      0.74     25000\n",
      "\n",
      "Confusion Matrix...: \n",
      "[[6050 1077   89]\n",
      " [2416 8938 1606]\n",
      " [  33 1311 3480]]\n"
     ]
    }
   ],
   "source": [
    "show_results(pipeline, x_train, y_train, x_test, y_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
